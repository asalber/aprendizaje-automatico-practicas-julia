{
  "hash": "0230de4f5ca1970f221ca77bd64629dd",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Regresión\nlang: es\n---\n\nLos modelos de aprendizaje basados en regresión son modelos bastante simples que pueden utilizarse para predecir variables cuantitativas (regresión lineal) o cualitativas (regresión logística). Esta práctica contiene ejercicios que muestran como construir modelos de aprendizaje de regresión lineal y regresión logística con Julia.\n\n## Ejercicios Resueltos\n\nPara la realización de esta práctica se requieren los siguientes paquetes:\n\n```julia\nusing CSV  # Para la lectura de archivos CSV.\nusing DataFrames  # Para el manejo de datos tabulares.\nusing PrettyTables  # Para mostrar tablas formateadas.\nusing Plots  # Para el dibujo de gráficas.\nusing GLMakie  # Para obtener gráficos interactivos.\n```\n\n:::{#exr-regresion-1}\nEl conjunto de datos `viviendas.csv` contiene información sobre el precio de venta de viviendas en una ciudad. \n\na.  Cargar los datos del archivo `viviendas.csv` en un data frame.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=1}\n    ``` {.julia .cell-code}\n    using CSV, DataFrames\n    df = CSV.read(\"datos/viviendas.csv\", DataFrame)\n    first(df, 5)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=2}\n    ```{=tex}\n    \\begin{tabular}{r|ccccccccc}\n    \t& precio & area & dormitorios & baños & habitaciones & calleprincipal & huespedes & sotano & \\\\\n    \t\\hline\n    \t& Int64 & Int64 & Int64 & Int64 & Int64 & String3 & String3 & String3 & \\\\\n    \t\\hline\n    \t1 & 13300000 & 7420 & 4 & 2 & 3 & si & no & no & $\\dots$ \\\\\n    \t2 & 12250000 & 8960 & 4 & 4 & 4 & si & no & no & $\\dots$ \\\\\n    \t3 & 12250000 & 9960 & 3 & 2 & 2 & si & no & si & $\\dots$ \\\\\n    \t4 & 12215000 & 7500 & 4 & 2 & 2 & si & no & si & $\\dots$ \\\\\n    \t5 & 11410000 & 7420 & 4 & 1 & 2 & si & si & si & $\\dots$ \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Dibujar un diagrama de dispersión entre el precio y el area de las viviendas.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=2}\n    ``` {.julia .cell-code}\n    using Plots\n    plt = scatter(df.area, df.precio, xlabel=\"Area\", ylabel=\"Precio\", title=\"Precio vs Area\", label = \"Ejemplos\", fmt=:png,)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=3}\n    ![](03-regresion_files/figure-pdf/cell-3-output-1.svg){fig-pos='H'}\n    :::\n    :::\n    \n    \n    :::\n\na.  Definir un modelo lineal que explique el precio en función del área de las viviendas.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Un modelo lineal tiene encuación $y = \\theta_1 + \\theta_2 x$.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=3}\n    ``` {.julia .cell-code}\n    precio(area, θ) = θ[1] .+ θ[2] * area\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=4}\n    ```\n    precio (generic function with 1 method)\n    ```\n    :::\n    :::\n    \n    \n    Observa que la función precio está vectorizada, lo que significa que puede recibir un vector de áreas y devolver un vector de precios.\n    :::\n\na.  Inicializar los parámetros del modelo lineal con valores nulos y dibujar el modelo sobre el diagrama de dispersión.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=4}\n    ``` {.julia .cell-code}\n    θ = [0.0, 0.0]\n    plot!(df.area, precio(df.area, θ), label = \"Modelo 0\")\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=5}\n    ![](03-regresion_files/figure-pdf/cell-5-output-1.svg){fig-pos='H'}\n    :::\n    :::\n    \n    \n    :::\n\na.  Definir una función de costo para el modelo lineal y evaluar el coste para el modelo lineal construido con los parámetros iniciales. A la vista del coste obtenido, ¿cómo de bueno es el modelo?\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    La función de coste para un modelo lineal es el error cuadrático medio.\n\n    $$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 $$\n\n    donde $h_\\theta$ es el modelo, $h_\\theta(x^{(i)})$ es la predicción del modelo para el ejemplo $i$-ésimo, $y^{(i)}$ es el valor real observado para el ejemplo $i$-ésimo, y $m$ es el número de ejemplos.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=5}\n    ``` {.julia .cell-code}\n    function coste(θ, X, Y)\n        m = length(Y)\n        return sum((precio(X, θ) .- Y).^2) / (2 * m)\n    end\n    \n    coste(θ, df.area, df.precio)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=6}\n    ```\n    1.3106916364659266e13\n    ```\n    :::\n    :::\n    \n    \n    La función de coste nos da una medida de lo lejos que están las predicciones del modelo de los valores reales observados. En este caso, el coste es muy alto, lo que indica que el modelo no es bueno.\n    :::\n\na.  ¿En qué dirección debemos modificar los parámetros del modelo para mejorar el modelo?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n    Para minimizar la función de coste, debemos modificar los parámetros del modelo en la dirección opuesta al gradiente de la función de coste, ya que el gradiente de una función indica la dirección de mayor crecimiento de la función.\n    :::\n\na.  Crear una función para modificar los pesos del modelo lineal mediante el algoritmo del gradiente descendente, y aplicarla a los parámetros actuales tomando una tasa de aprendizaje de $10^{-8}$. ¿Cómo han cambiado los parámetros del modelo? Dibujar el modelo actualizado sobre el diagrama de dispersión. ¿Cómo ha cambiado el coste?\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    El algoritmo del gradiente descendente actualiza los parámetros del modelo de acuerdo a la siguiente regla:\n\n    $$\n    \\theta_j = \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n    $$\n\n    donde $\\alpha$ es la tasa de aprendizaje y $\\frac{\\partial J(\\theta)}{\\partial \\theta_j}$ es la derivada parcial de la función de coste con respecto al parámetro $\\theta_j$.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=6}\n    ``` {.julia .cell-code}\n    function gradiente_descendente!(θ, X, Y, α)\n        # Calculamos el número de ejemplos\n        m = length(Y)\n        # Actualizamos el término independiente del modelo lineal.\n        θ[1] -= α * sum(precio(X, θ) - Y) / m\n        # Actualizamos la pendiente del modelo lineal.\n        θ[2] -= α * sum((precio(X, θ) - Y) .* X) / m\n        return θ\n    end\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=7}\n    ```\n    gradiente_descendente! (generic function with 1 method)\n    ```\n    :::\n    :::\n    \n    \n    Aplicamos la función a los parámetros del modelo actual y mostramos los nuevos parámetros.\n\n\n    ::: {.cell execution_count=7}\n    ``` {.julia .cell-code}\n    gradiente_descendente!(θ, df.area, df.precio, 1e-8)\n    θ\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=8}\n    ```\n    2-element Vector{Float64}:\n       0.04766729247706422\n     267.22919804579385\n    ```\n    :::\n    :::\n    \n    \n    Dibujamos el nuevo modelo.\n\n\n    ::: {.cell execution_count=8}\n    ``` {.julia .cell-code}\n    plot!(df.area, precio(df.area, θ), label = \"Modelo 1\")\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=9}\n    ![](03-regresion_files/figure-pdf/cell-9-output-1.svg){fig-pos='H'}\n    :::\n    :::\n    \n    \n    Se observa que ahora la recta está más cerca de la nube de puntos, por lo que el modelo ha mejorado. Calculamos el coste del nuevo modelo.\n\n\n    ::: {.cell execution_count=9}\n    ``` {.julia .cell-code}\n    coste(θ, df.area, df.precio)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=10}\n    ```\n    7.080823787113201e12\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Repetir el proceso de actualización de los parámetros del modelo mediante el algoritmo del gradiente descendente durante 9 iteraciones más y dibujar los modelos actualizados.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n    ```julia\n    for i = 2:10\n        gradiente_descendente!(θ, df.area, df.precio, 1e-8)\n        plot!(df.area, precio(df.area, θ), label = \"Modelo $i\", legend = true)\n    end\n    plt\n    ```\n\n    ![](img/regresion/modelos_regresion)\n    :::\n\na.  Dibujar un gráfico con la evolución del coste del modelo a lo largo de las iteraciones. ¿Cómo se comporta el coste a lo largo de las iteraciones?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=10}\n    ``` {.julia .cell-code}\n    costes = Float64[]\n    for i = 1:10\n        gradiente_descendente!(θ, df.area, df.precio, 1e-8)\n        push!(costes, coste(θ, df.area, df.precio))\n    end\n    costes\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=11}\n    ```\n    10-element Vector{Float64}:\n     4.230808760870044e12\n     2.882906194020343e12\n     2.2454213686913755e12\n     1.9439256128790886e12\n     1.8013344680594421e12\n     1.7338965877160208e12\n     1.7020021263374993e12\n     1.6869177748236997e12\n     1.6797836937723748e12\n     1.6764096595632322e12\n    ```\n    :::\n    :::\n    \n    \n    El coste del modelo disminuye en cada iteración, lo que indica que el modelo está mejorando. Esto se debe a que el algoritmo del gradiente descendente modifica los parámetros del modelo en la dirección que minimiza la función de coste.\n    :::\n\na.  ¿Hasta qué iteración habrá que llegar para conseguir un reducción del coste menor de un $0.0001\\%$?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=11}\n    ``` {.julia .cell-code}\n    θ = [0.0, 0.0]\n    costes = [0, coste(θ, df.area, df.precio)]\n    i = 1\n    while abs(costes[end] - costes[end-1]) / costes[end-1] > 0.000001\n        i += 1\n        gradiente_descendente!(θ, df.area, df.precio, 1e-8)\n        push!(costes, coste(θ, df.area, df.precio))\n    end\n    i\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=12}\n    ```\n    23\n    ```\n    :::\n    :::\n    \n    \n    En este caso, el algoritmo del gradiente descendente converge en 1000 iteraciones.\n    :::\n\na.  ¿Qué sucede si se utiliza una tasa de aprendizaje $\\alpha = 0.0001$? ¿Cómo afecta al coste y a la convergencia del modelo?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Solución\n\n\n    ::: {.cell execution_count=12}\n    ``` {.julia .cell-code}\n    θ = [0.0, 0.0]\n    costes = [coste(θ, df.area, df.precio)]\n    for i = 1:10\n        gradiente_descendente!(θ, df.area, df.precio, 0.0001)\n        push!(costes, coste(θ, df.area, df.precio))\n    end\n    costes\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=13}\n    ```\n    11-element Vector{Float64}:\n     1.3106916364659266e13\n     1.114133369099188e20\n     1.0856750832581238e27\n     1.05794371802143e34\n     1.0309206941949286e41\n     1.004587918634273e48\n     9.789277603492545e54\n     9.539230386975057e61\n     9.29557011881276e68\n     9.058133657380397e75\n     8.826762028174244e82\n    ```\n    :::\n    :::\n    \n    \n    Si la tasa de aprendizaje es demasiado grande, el algoritmo del gradiente descendente puede no converger y el coste puede oscilar en lugar de disminuir. En este caso, el coste aumenta en cada iteración, lo que indica que la tasa de aprendizaje es demasiado grande.\n    :::\n:::\n\n",
    "supporting": [
      "03-regresion_files/figure-pdf"
    ],
    "filters": []
  }
}