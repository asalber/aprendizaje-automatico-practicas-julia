{
  "hash": "5926da2e5f25303f6501b503f71dcde2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: √Årboles de decisi√≥n\nlang: es\n---\n\nLos √°rboles de decisi√≥n son modelos de aprendizaje simples e intuitivos que pueden utilizarse para tanto para predecir variables cuantitativas (regresi√≥n) como categ√≥ricas (clasificaci√≥n). Esta pr√°ctica contiene ejercicios que muestran como construir modelos de aprendizaje basados en √°rboles de decisi√≥n con Julia.\n\n## Ejercicios Resueltos\n\nPara la realizaci√≥n de esta pr√°ctica se requieren los siguientes paquetes:\n\n```julia\nusing CSV  # Para la lectura de archivos CSV.\nusing DataFrames  # Para el manejo de datos tabulares.\nusing Tidier # Para el preprocesamiento de datos.\nusing PrettyTables  # Para mostrar tablas formateadas.\nusing Plots  # Para el dibujo de gr√°ficas.\nusing GLMakie  # Para obtener gr√°ficos interactivos.\nusing AlgebraOfGraphics # Para generar gr√°ficos mediante la gram√°tica de gr√°ficos.\nusing DecisionTree # Para construir √°rboles de decisi√≥n.\nusing GraphMakie # Para la visualizaci√≥n de √°rboles de decisi√≥n.\n```\n\n:::{#exr-arboles-decision-1}\nEl conjunto de datos [`tenis.csv`](/datos/tenis.csv) contiene informaci√≥n sobre las condiciones meteorol√≥gicas de varios d√≠as y si se pudo jugar al tenis o no.\n\na.  Cargar los datos del archivo `tenis.csv` en un data frame.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=1}\n    ``` {.julia .cell-code}\n    using CSV, DataFrames\n    df = CSV.read(\"datos/tenis.csv\", DataFrame)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=2}\n    ```{=tex}\n    \\begin{tabular}{r|ccccc}\n    \t& Cielo & Temperatura & Humedad & Viento & Tenis\\\\\n    \t\\hline\n    \t& String15 & String15 & String7 & String7 & String3\\\\\n    \t\\hline\n    \t1 & Soleado & Caluroso & Alta & Suave & No \\\\\n    \t2 & Soleado & Caluroso & Alta & Fuerte & No \\\\\n    \t3 & Nublado & Caluroso & Alta & Suave & S√≠ \\\\\n    \t4 & Lluvioso & Moderado & Alta & Suave & S√≠ \\\\\n    \t5 & Lluvioso & Fr√≠o & Normal & Suave & S√≠ \\\\\n    \t6 & Lluvioso & Fr√≠o & Normal & Fuerte & No \\\\\n    \t7 & Nublado & Fr√≠o & Normal & Fuerte & S√≠ \\\\\n    \t8 & Soleado & Moderado & Alta & Suave & No \\\\\n    \t9 & Soleado & Fr√≠o & Normal & Suave & S√≠ \\\\\n    \t10 & Lluvioso & Moderado & Normal & Suave & S√≠ \\\\\n    \t11 & Soleado & Moderado & Normal & Fuerte & S√≠ \\\\\n    \t12 & Nublado & Moderado & Alta & Fuerte & S√≠ \\\\\n    \t13 & Nublado & Caluroso & Normal & Suave & S√≠ \\\\\n    \t14 & Lluvioso & Moderado & Alta & Fuerte & No \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Crear un diagrama de barras que muestre la distribuci√≥n de frecuencias de cada variable meteorol√≥gica seg√∫n si se pudo jugar al tenis o no. ¬øQu√© variable meteorol√≥gica parece tener m√°s influencia en la decisi√≥n de jugar al tenis?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=2}\n    ``` {.julia .cell-code}\n    using GLMakie, AlgebraOfGraphics\n    \n    function frecuencias(df::DataFrame, var::Symbol)\n        # Calculamos el n√∫mero de d√≠as de cada clase que se juega al tenis.\n        frec = combine(groupby(df, [var, :Tenis]), nrow => :D√≠as)\n        # Dibujamos el diagrama de barras.\n        plt = data(frec) * \n        mapping(var, :D√≠as, stack = :Tenis, color = :Tenis, ) * \n        visual(BarPlot) \n        # Devolvemos el gr√°fico.\n        return plt\n    end\n    \n    fig = Figure()\n    draw!(fig[1, 1], frecuencias(df, :Cielo))\n    draw!(fig[1, 2], frecuencias(df, :Temperatura))\n    draw!(fig[1, 3], frecuencias(df, :Humedad))\n    draw!(fig[1, 4], frecuencias(df, :Viento))\n    fig\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=3}\n    ![](07-arboles-decision_files/figure-pdf/cell-3-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n    A la vista de las frecuencias de cada variable, las variable `Cielo` y `Humedad` parecen ser las que m√°s influye en la decisi√≥n de jugar al tenis.\n    :::\n\na.  Calcular la impureza del conjunto de datos utilizando el √≠ndice de Gini. ¬øQu√© variable meteorol√≥gica parece tener m√°s influencia en la decisi√≥n de jugar al tenis?\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    El [√≠ndice de Gini](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) se calcula mediante la f√≥rmula\n    \n    $$ GI = 1 - \\sum_{i=1}^{n} p_i^2 $$\n\n    donde $p_i$ es la proporci√≥n de cada clase en el conjunto de datos y $n$ es el n√∫mero de clases.\n    \n    El √≠ndice de Gini toma valores entre $0$ y $1-\\frac{1}{n}$ ($0.5$ en el caso de clasificaci√≥n binaria), donde $0$ indica que todas las instancias pertenecen a una sola clase (m√≠nima impureza) y $1-\\frac{1}{n}$ indica que las instancias est√°n distribuidas uniformemente entre todas las clases (m√°xima impureza).\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=3}\n    ``` {.julia .cell-code}\n    function gini(df::DataFrame, var::Symbol)\n        # Calculamos el n√∫mero de ejemplos.\n        n = nrow(df)\n        # Calculamos las frecuencias absolutas de cada clase.\n        frec = combine(groupby(df, var), nrow => :ni)\n        # Calculamos la proporci√≥n de cada clase.\n        frec.p = frec.ni ./ n\n        # Calculamos el √≠ndice de Gini.\n        gini = 1 - sum(frec.p .^ 2)\n        return gini\n    end\n    \n    g0 = gini(df, :Tenis)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=4}\n    ```\n    0.4591836734693877\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  ¬øQu√© reducci√≥n del √≠ndice Gini se obtiene si dividimos el conjunto de ejemplos seg√∫n la variable `Humedad`? ¬øY si dividimos el conjunto con respecto a la variable `Viento`?\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    La reducci√≥n del √≠ndice de Gini se calcula como la diferencia entre el √≠ndice de Gini del conjunto original y el √≠ndice de Gini del conjunto dividido.\n    \n    $$ \\Delta GI = GI_{original} - GI_{dividido} $$\n\n    donde el √≠ndice de Gini del conjunto dividido es la media ponderada de los √≠ndices de Gini de los subconjuntos resultantes de la divisi√≥n.\n    :::\n    \n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n    Calculamos primero la reducci√≥n del √≠ndice de Gini al dividir el conjunto de ejemplos seg√∫n la variable `Humedad`.\n\n\n    ::: {.cell execution_count=4}\n    ``` {.julia .cell-code}\n    using Tidier\n    # Dividimos el conjunto de ejemplos seg√∫n la variable Humedad.\n    df_humedad_alta = @filter(df, Humedad == \"Alta\")\n    df_humedad_normal = @filter(df, Humedad == \"Normal\")\n    # Calculamos los tama√±os de los subconjuntos de ejemplos.\n    n = nrow(df_humedad_alta), nrow(df_humedad_normal)\n    # Calculamos el √≠ndice de Gini de cada subconjunto.\n    gis = gini(df_humedad_alta, :Tenis), gini(df_humedad_normal, :Tenis)\n    # Calculamos media ponderada de los √≠ndices de Gini de los subconjuntos \n    g_humedad = sum(gis .* n) / sum(n)\n    # Calculamos la reducci√≥n del √≠ndice de Gini.\n    g0 - g_humedad\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=5}\n    ```\n    0.09183673469387743\n    ```\n    :::\n    :::\n    \n    \n    Calculamos ahora la reducci√≥n del √≠ndice de Gini al dividir el conjunto de ejemplos seg√∫n la variable `Viento`.\n\n\n    ::: {.cell execution_count=5}\n    ``` {.julia .cell-code}\n    # Dividimos el conjunto de ejemplos seg√∫n la variable `Viento`\n    df_viento_fuerte = @filter(df, Viento == \"Fuerte\")\n    df_viento_suave = @filter(df, Viento == \"Suave\")\n    # Calculamos los tama√±os de los subconjuntos de ejemplos\n    n = nrow(df_viento_fuerte), nrow(df_viento_suave)\n    # Calculamos el √≠ndice de Gini de cada subconjunto\n    gis = gini(df_viento_fuerte, :Tenis), gini(df_viento_suave, :Tenis)\n    # Calculamos media ponderada de los √≠ndices de Gini de los subconjuntos\n    g_viento = sum(gis .* n) / sum(n)\n    # Calculamos la reducci√≥n del √≠ndice de Gini\n    g0 - g_viento\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=6}\n    ```\n    0.030612244897959162\n    ```\n    :::\n    :::\n    \n    \n    Como se puede observar, la reducci√≥n del √≠ndice de Gini al dividir el conjunto de ejemplos seg√∫n la variable `Humedad` es mayor que la reducci√≥n del √≠ndice de Gini al dividir el conjunto con respecto a la variable `Viento`. Por lo tanto, la variable `Humedad` parece tener m√°s influencia en la decisi√≥n de jugar al tenis y ser√≠a la variable que se deber√≠a elegir para dividir el conjunto de ejemplos.\n    :::\n\na.  Construir un √°rbol de decisi√≥n que explique si se puede jugar al tenis en funci√≥n de las variables meteorol√≥gicas.\n    \n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n `DecisionTreeClassifier` del paquete [`DecisionTree.jl`](https://docs.juliahub.com/DecisionTree/). \n\n    Los par√°metros m√°s importantes de esta funci√≥n son:\n\n    - `max_depth`: Profundidad m√°xima del √°rbol. Si no se indica, el √°rbol crecer√° hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos de `min_samples_split` ejemplos.\n    - `min_samples_leaf`: N√∫mero m√≠nimo de ejemplos en una hoja (1 por defecto).\n    - `min_samples_split`: N√∫mero m√≠nimo de ejemplos para dividir un nodo (2 por defecto).\n    - `min_impurity_decrease`: Reducci√≥n m√≠nima de la impureza para dividir un nodo (0 por defecto).\n    - `post-prune`: Si se indica `true`, se poda el √°rbol despu√©s de que se ha construido. La poda reduce el tama√±o del √°rbol eliminando nodos que no aportan informaci√≥n √∫til.\n    - `merge_purity_threshold`: Umbral de pureza para fusionar nodos. Si se indica, se fusionan los nodos que tienen una pureza menor que este umbral.\n    - `feature_importance`: Indica la medida para calcular la importancia de las variables a la hora de dividir el conjunto de datos. Puede ser `:impurity` o `:split`. Si no se indica, se utiliza la impureza de Gini.\n    - `rng`: Indica la semilla para la generaci√≥n de n√∫meros aleatorios. Si no se indica, se utiliza el generador de n√∫meros aleatorios por defecto.\n    :::\n    \n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=6}\n    ``` {.julia .cell-code}\n    using DecisionTree, CategoricalArrays\n    # Variables predictoras.\n    X = Matrix(select(df, Not(:Tenis)))\n    # Variable objetivo.\n    y = df.Tenis\n    # Convertir las variables categ√≥ricas a enteros.\n    X = hcat([levelcode.(categorical(X[:, j])) for j in 1:size(X, 2)]...)\n    # Convertir la variable objetivo a enteros.\n    y = levelcode.(categorical(y))\n    tree = DecisionTreeClassifier(max_depth=3)\n    fit!(tree, X, y)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=7}\n    ```\n    DecisionTreeClassifier\n    max_depth:                3\n    min_samples_leaf:         1\n    min_samples_split:        2\n    min_purity_increase:      0.0\n    pruning_purity_threshold: 1.0\n    n_subfeatures:            0\n    classes:                  [1, 2]\n    root:                     Decision Tree\n    Leaves: 6\n    Depth:  3\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Visualizar el √°rbol de decisi√≥n construido.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n `plot_tree` del paquete [`DecisionTree.jl`](https://docs.juliahub.com/DecisionTree/).\n    :::\n    \n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=7}\n    ``` {.julia .cell-code}\n    print_tree(tree, feature_names=names(df)[1:end-1])\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    Feature 3: \"Humedad\" < 2.0 ?\n    ‚îú‚îÄ Feature 1: \"Cielo\" < 3.0 ?\n        ‚îú‚îÄ Feature 1: \"Cielo\" < 2.0 ?\n            ‚îú‚îÄ 2 : 1/2\n            ‚îî‚îÄ 2 : 2/2\n        ‚îî‚îÄ 1 : 3/3\n    ‚îî‚îÄ Feature 4: \"Viento\" < 2.0 ?\n        ‚îú‚îÄ Feature 1: \"Cielo\" < 2.0 ?\n            ‚îú‚îÄ 1 : 1/1\n            ‚îî‚îÄ 2 : 2/2\n        ‚îî‚îÄ 2 : 4/4\n    ```\n    :::\n    :::\n    \n    \n    :::\n:::\n\n:::{#exr-arboles-decision-2}\nEl conjunto de datos [ping√ºinos.csv]() contiene un conjunto de datos sobre tres eEspecie de ping√ºinos con las siguientes variables:\n\n- Especie: Especie de ping√ºino, com√∫nmente Adelie, Chinstrap o Gentoo.\n- Isla: Isla del archipi√©lago Palmer donde se realiz√≥ la observaci√≥n.\n- Longitud_pico: Longitud del pico en mm.\n- Profundidad_pico: Profundidad del pico en mm\n- Longitud_ala: Longitud de la aleta en mm.\n- Peso: Masa corporal en gramos.\n- Sexo: Sexo\n\na.  Cargar los datos del archivo `pingu√Ønos.csv` en un data frame.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=8}\n    ``` {.julia .cell-code}\n    using CSV, DataFrames\n    df = CSV.read(\"datos/ping√ºinos.csv\", DataFrame, missingstring=\"NA\")\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=9}\n    ```{=tex}\n    \\begin{tabular}{r|ccccccc}\n    \t& Especie & Isla & Longitud\\_pico & Profundidad\\_pico & Longitud\\_ala & Peso & Sexo\\\\\n    \t\\hline\n    \t& String15 & String15 & Float64? & Float64? & Int64? & Int64? & String7?\\\\\n    \t\\hline\n    \t1 & Adelie & Torgersen & 39.1 & 18.7 & 181 & 3750 & macho \\\\\n    \t2 & Adelie & Torgersen & 39.5 & 17.4 & 186 & 3800 & hembra \\\\\n    \t3 & Adelie & Torgersen & 40.3 & 18.0 & 195 & 3250 & hembra \\\\\n    \t4 & Adelie & Torgersen & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} \\\\\n    \t5 & Adelie & Torgersen & 36.7 & 19.3 & 193 & 3450 & hembra \\\\\n    \t6 & Adelie & Torgersen & 39.3 & 20.6 & 190 & 3650 & macho \\\\\n    \t7 & Adelie & Torgersen & 38.9 & 17.8 & 181 & 3625 & hembra \\\\\n    \t8 & Adelie & Torgersen & 39.2 & 19.6 & 195 & 4675 & macho \\\\\n    \t9 & Adelie & Torgersen & 34.1 & 18.1 & 193 & 3475 & \\emph{missing} \\\\\n    \t10 & Adelie & Torgersen & 42.0 & 20.2 & 190 & 4250 & \\emph{missing} \\\\\n    \t11 & Adelie & Torgersen & 37.8 & 17.1 & 186 & 3300 & \\emph{missing} \\\\\n    \t12 & Adelie & Torgersen & 37.8 & 17.3 & 180 & 3700 & \\emph{missing} \\\\\n    \t13 & Adelie & Torgersen & 41.1 & 17.6 & 182 & 3200 & hembra \\\\\n    \t14 & Adelie & Torgersen & 38.6 & 21.2 & 191 & 3800 & macho \\\\\n    \t15 & Adelie & Torgersen & 34.6 & 21.1 & 198 & 4400 & macho \\\\\n    \t16 & Adelie & Torgersen & 36.6 & 17.8 & 185 & 3700 & hembra \\\\\n    \t17 & Adelie & Torgersen & 38.7 & 19.0 & 195 & 3450 & hembra \\\\\n    \t18 & Adelie & Torgersen & 42.5 & 20.7 & 197 & 4500 & macho \\\\\n    \t19 & Adelie & Torgersen & 34.4 & 18.4 & 184 & 3325 & hembra \\\\\n    \t20 & Adelie & Torgersen & 46.0 & 21.5 & 194 & 4200 & macho \\\\\n    \t21 & Adelie & Biscoe & 37.8 & 18.3 & 174 & 3400 & hembra \\\\\n    \t22 & Adelie & Biscoe & 37.7 & 18.7 & 180 & 3600 & macho \\\\\n    \t23 & Adelie & Biscoe & 35.9 & 19.2 & 189 & 3800 & hembra \\\\\n    \t24 & Adelie & Biscoe & 38.2 & 18.1 & 185 & 3950 & macho \\\\\n    \t25 & Adelie & Biscoe & 38.8 & 17.2 & 180 & 3800 & macho \\\\\n    \t26 & Adelie & Biscoe & 35.3 & 18.9 & 187 & 3800 & hembra \\\\\n    \t27 & Adelie & Biscoe & 40.6 & 18.6 & 183 & 3550 & macho \\\\\n    \t28 & Adelie & Biscoe & 40.5 & 17.9 & 187 & 3200 & hembra \\\\\n    \t29 & Adelie & Biscoe & 37.9 & 18.6 & 172 & 3150 & hembra \\\\\n    \t30 & Adelie & Biscoe & 40.5 & 18.9 & 180 & 3950 & macho \\\\\n    \t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Hacer un an√°lisis de los datos perdidos en el data frame. \n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=9}\n    ``` {.julia .cell-code}\n    describe(df, :nmissing)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=10}\n    ```{=tex}\n    \\begin{tabular}{r|cc}\n    \t& variable & nmissing\\\\\n    \t\\hline\n    \t& Symbol & Int64\\\\\n    \t\\hline\n    \t1 & Especie & 0 \\\\\n    \t2 & Isla & 0 \\\\\n    \t3 & Longitud\\_pico & 2 \\\\\n    \t4 & Profundidad\\_pico & 2 \\\\\n    \t5 & Longitud\\_ala & 2 \\\\\n    \t6 & Peso & 2 \\\\\n    \t7 & Sexo & 11 \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Eliminar del data frame los casos con valores perdidos.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=10}\n    ``` {.julia .cell-code}\n    dropmissing!(df)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=11}\n    ```{=tex}\n    \\begin{tabular}{r|ccccccc}\n    \t& Especie & Isla & Longitud\\_pico & Profundidad\\_pico & Longitud\\_ala & Peso & Sexo\\\\\n    \t\\hline\n    \t& String15 & String15 & Float64 & Float64 & Int64 & Int64 & String7\\\\\n    \t\\hline\n    \t1 & Adelie & Torgersen & 39.1 & 18.7 & 181 & 3750 & macho \\\\\n    \t2 & Adelie & Torgersen & 39.5 & 17.4 & 186 & 3800 & hembra \\\\\n    \t3 & Adelie & Torgersen & 40.3 & 18.0 & 195 & 3250 & hembra \\\\\n    \t4 & Adelie & Torgersen & 36.7 & 19.3 & 193 & 3450 & hembra \\\\\n    \t5 & Adelie & Torgersen & 39.3 & 20.6 & 190 & 3650 & macho \\\\\n    \t6 & Adelie & Torgersen & 38.9 & 17.8 & 181 & 3625 & hembra \\\\\n    \t7 & Adelie & Torgersen & 39.2 & 19.6 & 195 & 4675 & macho \\\\\n    \t8 & Adelie & Torgersen & 41.1 & 17.6 & 182 & 3200 & hembra \\\\\n    \t9 & Adelie & Torgersen & 38.6 & 21.2 & 191 & 3800 & macho \\\\\n    \t10 & Adelie & Torgersen & 34.6 & 21.1 & 198 & 4400 & macho \\\\\n    \t11 & Adelie & Torgersen & 36.6 & 17.8 & 185 & 3700 & hembra \\\\\n    \t12 & Adelie & Torgersen & 38.7 & 19.0 & 195 & 3450 & hembra \\\\\n    \t13 & Adelie & Torgersen & 42.5 & 20.7 & 197 & 4500 & macho \\\\\n    \t14 & Adelie & Torgersen & 34.4 & 18.4 & 184 & 3325 & hembra \\\\\n    \t15 & Adelie & Torgersen & 46.0 & 21.5 & 194 & 4200 & macho \\\\\n    \t16 & Adelie & Biscoe & 37.8 & 18.3 & 174 & 3400 & hembra \\\\\n    \t17 & Adelie & Biscoe & 37.7 & 18.7 & 180 & 3600 & macho \\\\\n    \t18 & Adelie & Biscoe & 35.9 & 19.2 & 189 & 3800 & hembra \\\\\n    \t19 & Adelie & Biscoe & 38.2 & 18.1 & 185 & 3950 & macho \\\\\n    \t20 & Adelie & Biscoe & 38.8 & 17.2 & 180 & 3800 & macho \\\\\n    \t21 & Adelie & Biscoe & 35.3 & 18.9 & 187 & 3800 & hembra \\\\\n    \t22 & Adelie & Biscoe & 40.6 & 18.6 & 183 & 3550 & macho \\\\\n    \t23 & Adelie & Biscoe & 40.5 & 17.9 & 187 & 3200 & hembra \\\\\n    \t24 & Adelie & Biscoe & 37.9 & 18.6 & 172 & 3150 & hembra \\\\\n    \t25 & Adelie & Biscoe & 40.5 & 18.9 & 180 & 3950 & macho \\\\\n    \t26 & Adelie & Dream & 39.5 & 16.7 & 178 & 3250 & hembra \\\\\n    \t27 & Adelie & Dream & 37.2 & 18.1 & 178 & 3900 & macho \\\\\n    \t28 & Adelie & Dream & 39.5 & 17.8 & 188 & 3300 & hembra \\\\\n    \t29 & Adelie & Dream & 40.9 & 18.9 & 184 & 3900 & macho \\\\\n    \t30 & Adelie & Dream & 36.4 & 17.0 & 195 & 3325 & hembra \\\\\n    \t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Crear diagramas que muestren la distribuci√≥n de frecuencias de cada variable seg√∫n la especie de ping√ºino. ¬øQu√© variable parece tener m√°s influencia en la especie de ping√ºino?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n    Para las variables cualitativas dibujamos diagramas de barras.\n\n\n    ::: {.cell execution_count=11}\n    ``` {.julia .cell-code}\n    using GLMakie, AlgebraOfGraphics\n    \n    frec_isla = combine(groupby(df, [:Isla, :Especie]), nrow => :Frecuencia)\n    data(frec_isla) * \n        mapping(:Isla, :Frecuencia, stack = :Especie, color =:Especie) *\n        visual(BarPlot) |> draw\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=12}\n    ![](07-arboles-decision_files/figure-pdf/cell-12-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n\n    ::: {.cell execution_count=12}\n    ``` {.julia .cell-code}\n    frec_sexo = combine(groupby(df, [:Sexo, :Especie]), nrow => :Frecuencia)\n    data(frec_sexo) * \n        mapping(:Sexo, :Frecuencia, stack = :Especie, color =:Especie) *\n        visual(BarPlot) |> draw\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=13}\n    ![](07-arboles-decision_files/figure-pdf/cell-13-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n    Para las variables cuantitativas dibujamos diagramas de cajas.\n\n\n    ::: {.cell execution_count=13}\n    ``` {.julia .cell-code}\n    function cajas(df, var, clase)\n        data(df) *\n            mapping(clase, var, color = clase) *\n            visual(BoxPlot) |> \n            draw\n    end\n    \n    cajas(df, :Longitud_pico, :Especie)\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=14}\n    ![](07-arboles-decision_files/figure-pdf/cell-14-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n\n    ::: {.cell execution_count=14}\n    ``` {.julia .cell-code}\n    cajas(df, :Profundidad_pico, :Especie)\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=15}\n    ![](07-arboles-decision_files/figure-pdf/cell-15-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n\n    ::: {.cell execution_count=15}\n    ``` {.julia .cell-code}\n    cajas(df, :Longitud_ala, :Especie)\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=16}\n    ![](07-arboles-decision_files/figure-pdf/cell-16-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n\n    ::: {.cell execution_count=16}\n    ``` {.julia .cell-code}\n    cajas(df, :Peso, :Especie)\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=17}\n    ![](07-arboles-decision_files/figure-pdf/cell-17-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n    :::\n\na.  ¬øCu√°l es la reducci√≥n de la impureza del conjunto de datos si dividimos el conjunto de datos en dos conjuntos seg√∫n si la longitud del pico es mayor o menor que 44 mm?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=17}\n    ``` {.julia .cell-code}\n    using Tidier\n    function gini(df::DataFrame, var::Symbol)\n        n = nrow(df)\n        frec = combine(groupby(df, var), nrow => :ni)\n        frec.p = frec.ni ./ n\n        gini = 1 - sum(frec.p .^ 2)\n        return gini\n    end\n    \n    function reduccion_impureza(df::DataFrame, var::Symbol, val::Number)\n        # Dividimos el conjunto de ejemplos seg√∫n la longitud del pico es menor de 44.\n        df_menor = @eval @filter($df, $var <= $val)\n        df_mayor = @eval @filter($df, $var > $val)\n        # Calculamos los tama√±os de los subconjuntos de ejemplos.\n        n = nrow(df_menor), nrow(df_mayor)\n        # Calculamos el √≠ndice de Gini de cada subconjunto.\n        gis = gini(df_menor, :Especie), gini(df_mayor, :Especie)\n        # Calculamos media ponderada de los √≠ndices de Gini de los subconjuntos.\n        g1 = sum(gis .* n) / sum(n)\n        # Calculamos la reducci√≥n del √≠ndice de Gini.\n        gini(df, :Especie) - g1\n    end\n    \n    reduccion_impureza(df, :Longitud_pico, 44)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=18}\n    ```\n    0.26577182779353914\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Determinar el valor √≥ptimo de divisi√≥n del conjunto de datos seg√∫n la longitud del pico. Para ello, calcular la reducci√≥n de la impureza para cada valor de longitud del pico y dibujar el resultado.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n    Dibujamos la reducci√≥n de la impureza en funci√≥n de la longitud del pico.\n\n\n    ::: {.cell execution_count=18}\n    ``` {.julia .cell-code}\n    using Plots\n    # Valores √∫nicos de longitud del pico.\n    valores = unique(df.Longitud_pico)\n    # Reducci√≥n de la impureza para cada valor.\n    reducciones = [reduccion_impureza(df, :Longitud_pico, val) for val in valores]\n    # Graficamos el resultado.\n    Plots.scatter(valores, reducciones, xlabel = \"Longitud del pico\", ylabel = \"Reducci√≥n de la impureza\", legend = false)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=19}\n    ![](07-arboles-decision_files/figure-pdf/cell-19-output-1.svg){fig-pos='H'}\n    :::\n    :::\n    \n    \n    Y ahora obtenemos el valor √≥ptimo de divisi√≥n del conjunto de datos seg√∫n la longitud del pico.\n\n\n    ::: {.cell execution_count=19}\n    ``` {.julia .cell-code}\n    val_optimo = valores[argmax(reducciones)]\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=20}\n    ```\n    42.3\n    ```\n    :::\n    :::\n    \n    \n    ::: \n\na.  Dividir aleatoriamente el dataframe en un conjunto de entrenamiento y un conjunto de test con proporciones $3/4$ y $1/4$ respectivamente.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la funci√≥n [`shuffle`](https://docs.julialang.org/en/v1/stdlib/Random/#Random.shuffle) del paquete [`Random`](https://docs.julialang.org/en/v1/stdlib/Random/) para barajar el dataframe y luego dividirlo en dos subconjuntos.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n    \n\n\n    ::: {.cell execution_count=20}\n    ``` {.julia .cell-code}\n    using Random\n    # Establecemos la semilla para la reproducibilidad.\n    Random.seed!(1234)\n    # Barajamos el dataframe.\n    df = shuffle(df)\n    # Dividimos el dataframe en un conjunto de entrenamiento y un conjunto de test.\n    n = nrow(df)\n    df_test = df[1:div(n, 4), :]\n    df_train = df[div(n, 4)+1:end, :]\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=21}\n    ```{=tex}\n    \\begin{tabular}{r|ccccccc}\n    \t& Especie & Isla & Longitud\\_pico & Profundidad\\_pico & Longitud\\_ala & Peso & Sexo\\\\\n    \t\\hline\n    \t& String15 & String15 & Float64 & Float64 & Int64 & Int64 & String7\\\\\n    \t\\hline\n    \t1 & Adelie & Dream & 39.0 & 18.7 & 185 & 3650 & macho \\\\\n    \t2 & Chinstrap & Dream & 52.8 & 20.0 & 205 & 4550 & macho \\\\\n    \t3 & Chinstrap & Dream & 55.8 & 19.8 & 207 & 4000 & macho \\\\\n    \t4 & Adelie & Torgersen & 35.1 & 19.4 & 193 & 4200 & macho \\\\\n    \t5 & Adelie & Torgersen & 34.6 & 21.1 & 198 & 4400 & macho \\\\\n    \t6 & Gentoo & Biscoe & 50.0 & 15.2 & 218 & 5700 & macho \\\\\n    \t7 & Chinstrap & Dream & 50.6 & 19.4 & 193 & 3800 & macho \\\\\n    \t8 & Chinstrap & Dream & 43.5 & 18.1 & 202 & 3400 & hembra \\\\\n    \t9 & Adelie & Dream & 36.9 & 18.6 & 189 & 3500 & hembra \\\\\n    \t10 & Adelie & Dream & 36.6 & 18.4 & 184 & 3475 & hembra \\\\\n    \t11 & Chinstrap & Dream & 46.6 & 17.8 & 193 & 3800 & hembra \\\\\n    \t12 & Gentoo & Biscoe & 50.8 & 17.3 & 228 & 5600 & macho \\\\\n    \t13 & Chinstrap & Dream & 52.2 & 18.8 & 197 & 3450 & macho \\\\\n    \t14 & Adelie & Dream & 39.6 & 18.8 & 190 & 4600 & macho \\\\\n    \t15 & Adelie & Torgersen & 42.8 & 18.5 & 195 & 4250 & macho \\\\\n    \t16 & Adelie & Biscoe & 36.5 & 16.6 & 181 & 2850 & hembra \\\\\n    \t17 & Gentoo & Biscoe & 49.1 & 14.8 & 220 & 5150 & hembra \\\\\n    \t18 & Chinstrap & Dream & 43.2 & 16.6 & 187 & 2900 & hembra \\\\\n    \t19 & Gentoo & Biscoe & 43.3 & 13.4 & 209 & 4400 & hembra \\\\\n    \t20 & Gentoo & Biscoe & 49.5 & 16.1 & 224 & 5650 & macho \\\\\n    \t21 & Adelie & Biscoe & 37.8 & 20.0 & 190 & 4250 & macho \\\\\n    \t22 & Gentoo & Biscoe & 50.4 & 15.3 & 224 & 5550 & macho \\\\\n    \t23 & Adelie & Biscoe & 45.6 & 20.3 & 191 & 4600 & macho \\\\\n    \t24 & Chinstrap & Dream & 45.4 & 18.7 & 188 & 3525 & hembra \\\\\n    \t25 & Adelie & Dream & 39.2 & 18.6 & 190 & 4250 & macho \\\\\n    \t26 & Gentoo & Biscoe & 48.4 & 14.4 & 203 & 4625 & hembra \\\\\n    \t27 & Adelie & Torgersen & 35.2 & 15.9 & 186 & 3050 & hembra \\\\\n    \t28 & Gentoo & Biscoe & 48.4 & 16.3 & 220 & 5400 & macho \\\\\n    \t29 & Adelie & Dream & 33.1 & 16.1 & 178 & 2900 & hembra \\\\\n    \t30 & Adelie & Dream & 36.8 & 18.5 & 193 & 3500 & hembra \\\\\n    \t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Construir un √°rbol de decisi√≥n con el conjunto de entrenamiento sin tener en cuenta la variable `Isla` y visualizarlo.\n    \n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=21}\n    ``` {.julia .cell-code}\n    using DecisionTree, CategoricalArrays\n    # Variables predictivas.\n    X_train = Matrix(select(df_train, Not(:Isla, :Especie)))\n    # Variable objetivo.\n    y_train = df_train.Especie\n    # Convertir las variables categ√≥ricas a enteros.\n    X_train = hcat([levelcode.(categorical(X_train[:, j])) for j in 1:size(X_train, 2)]...)\n    # Convertir la variable objetivo a enteros\n    y_train = levelcode.(categorical(y_train))\n    \n    # Construimos el √°rbol de decisi√≥n con profundidad m√°xima 3.\n    tree = DecisionTreeClassifier(max_depth = 3)\n    fit!(tree, X_train, y_train)\n    print_tree(tree, feature_names=names(df)[3:end])\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    Feature 3: \"Longitud_ala\" < 29.0 ?\n    ‚îú‚îÄ Feature 1: \"Longitud_pico\" < 62.0 ?\n        ‚îú‚îÄ 1 : 96/96\n        ‚îî‚îÄ Feature 1: \"Longitud_pico\" < 87.0 ?\n            ‚îú‚îÄ 2 : 10/20\n            ‚îî‚îÄ 2 : 37/38\n    ‚îî‚îÄ Feature 2: \"Profundidad_pico\" < 46.0 ?\n        ‚îú‚îÄ 3 : 90/90\n        ‚îî‚îÄ Feature 1: \"Longitud_pico\" < 109.0 ?\n            ‚îú‚îÄ 1 : 2/2\n            ‚îî‚îÄ 2 : 4/4\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Predecir la especie de los ping√ºinos del conjunto de test y calcular la matriz de confusi√≥n de las predicciones.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Utilizar la funci√≥n [`confmat`](https://juliaai.github.io/StatisticalMeasures.jl/stable/confusion_matrices/#StatisticalMeasures.ConfusionMatrices.confmat) del paquete [`StatisticalMeaures`](https://juliaai.github.io/StatisticalMeasures.jl) para barajar el dataframe y luego dividirlo en dos subconjuntos.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=22}\n    ``` {.julia .cell-code}\n    using StatisticalMeasures\n    # Variables predictivas\n    X_test = Matrix(select(df_test, Not(:Isla, :Especie)))\n    # Variable objetivo\n    y_test = df_test.Especie\n    # Convertir las variables categ√≥ricas a enteros\n    X_test = hcat([levelcode.(categorical(X_test[:, j])) for j in 1:size(X_test, 2)]...)\n    # Convertir la variable objetivo a enteros\n    y_test = levelcode.(categorical(y_test))\n    # Predecimos la especie de ping√ºino del conjunto de test\n    y_pred = predict(tree, X_test)\n    # Calculamos la precisi√≥n del modelo\n    confmat(y_pred, y_test)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=23}\n    ```\n              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n              ‚îÇ Ground Truth ‚îÇ\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇPredicted‚îÇ 1  ‚îÇ 2  ‚îÇ 3  ‚îÇ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ    1    ‚îÇ 38 ‚îÇ 11 ‚îÇ 9  ‚îÇ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ    2    ‚îÇ 0  ‚îÇ 6  ‚îÇ 0  ‚îÇ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ    3    ‚îÇ 0  ‚îÇ 0  ‚îÇ 19 ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Calcular la precisi√≥n del modelo.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    La precisi√≥n es la proporci√≥n de predicciones correctas sobre el total de predicciones.\n\n    Utilizar la funci√≥n [`accuracy`](https://juliaai.github.io/StatisticalMeasures.jl/stable/auto_generated_list_of_measures/#StatisticalMeasures.Accuracy) del paquete [`StatisticalMeaures`](https://juliaai.github.io/StatisticalMeasures.jl) para calcular la precisi√≥n del modelo.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=23}\n    ``` {.julia .cell-code}\n    # Calculamos la precisi√≥n del modelo\n    accuracy(y_pred, y_test)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=24}\n    ```\n    0.7590361445783133\n    ```\n    :::\n    :::\n    \n    \n    :::\n\n:::\n\n:::{#exr-arboles-decision-3}\nEl fichero [`vinos.csv`](datos/vinos.csv) contiene informaci√≥n sobre las caracter√≠sticas de una muestra de vinos portugueses de la denominaci√≥n \"Vinho Verde\". Las variables que contiene son:\n\n| Variable             | Descripci√≥n                                                           | Tipo (unidades)        |\n|----------------------------------------|-----------------------------------------------------------------------|------------------------|\n| tipo                 | Tipo de vino                                                          | Categ√≥rica (blanco, tinto) |\n| meses.barrica        | Mesesde envejecimiento en barrica                               | Num√©rica(meses)  |\n| acided.fija          | Cantidadde √°cidotart√°rico                                 | Num√©rica(g/dm3)  |\n| acided.volatil       | Cantidad de √°cido ac√©tico                                             | Num√©rica(g/dm3)  |\n| acido.citrico        | Cantidad de √°cidoc√≠trico                                        | Num√©rica(g/dm3)  |\n| azucar.residual      | Cantidad de az√∫carremanente despu√©s de la fermentaci√≥n          | Num√©rica(g/dm3)  |\n| cloruro.sodico       | Cantidad de cloruros√≥dico                                       | Num√©rica(g/dm3)  |\n| dioxido.azufre.libre | Cantidad de di√≥xido de azufreen formalibre                | Num√©rica(mg/dm3) |\n| dioxido.azufre.total | Cantidadde di√≥xido de azufretotal en forma libre o ligada | Num√©rica(mg/dm3) |\n| densidad             | Densidad                                                              | Num√©rica(g/cm3)  |\n| ph                   | pH                                                                    | Num√©rica(0-14)   |\n| sulfatos             | Cantidadde sulfato de potasio                                   | Num√©rica(g/dm3)  |\n| alcohol              | Porcentajede contenidode alcohol                          | Num√©rica(0-100)  |\n| calidad              | Calificaci√≥n otorgada porun panel de expertos                   | Num√©rica(0-10)   |\n\na.  Crear un data frame con los datos de los vinos a partir del fichero [`vinos.csv`](datos/vinos.csv).\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=24}\n    ``` {.julia .cell-code}\n    using CSV, DataFrames\n    df = CSV.read(\"datos/vinos.csv\", DataFrame)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=25}\n    ```{=tex}\n    \\begin{tabular}{r|ccccccc}\n    \t& tipo & meses\\_barrica & acided\\_fija & acided\\_volatil & acido\\_citrico & azucar\\_residual & \\\\\n    \t\\hline\n    \t& String7 & Int64 & Float64 & Float64 & Float64 & Float64 & \\\\\n    \t\\hline\n    \t1 & blanco & 0 & 7.0 & 0.27 & 0.36 & 20.7 & $\\dots$ \\\\\n    \t2 & blanco & 0 & 6.3 & 0.3 & 0.34 & 1.6 & $\\dots$ \\\\\n    \t3 & blanco & 0 & 8.1 & 0.28 & 0.4 & 6.9 & $\\dots$ \\\\\n    \t4 & blanco & 0 & 7.2 & 0.23 & 0.32 & 8.5 & $\\dots$ \\\\\n    \t5 & blanco & 0 & 6.2 & 0.32 & 0.16 & 7.0 & $\\dots$ \\\\\n    \t6 & blanco & 0 & 8.1 & 0.22 & 0.43 & 1.5 & $\\dots$ \\\\\n    \t7 & blanco & 0 & 8.1 & 0.27 & 0.41 & 1.45 & $\\dots$ \\\\\n    \t8 & blanco & 0 & 8.6 & 0.23 & 0.4 & 4.2 & $\\dots$ \\\\\n    \t9 & blanco & 0 & 7.9 & 0.18 & 0.37 & 1.2 & $\\dots$ \\\\\n    \t10 & blanco & 0 & 6.6 & 0.16 & 0.4 & 1.5 & $\\dots$ \\\\\n    \t11 & blanco & 0 & 8.3 & 0.42 & 0.62 & 19.25 & $\\dots$ \\\\\n    \t12 & blanco & 0 & 6.6 & 0.17 & 0.38 & 1.5 & $\\dots$ \\\\\n    \t13 & blanco & 0 & 6.3 & 0.48 & 0.04 & 1.1 & $\\dots$ \\\\\n    \t14 & blanco & 0 & 6.2 & 0.66 & 0.48 & 1.2 & $\\dots$ \\\\\n    \t15 & blanco & 0 & 7.4 & 0.34 & 0.42 & 1.1 & $\\dots$ \\\\\n    \t16 & blanco & 0 & 6.5 & 0.31 & 0.14 & 7.5 & $\\dots$ \\\\\n    \t17 & blanco & 0 & 6.4 & 0.31 & 0.38 & 2.9 & $\\dots$ \\\\\n    \t18 & blanco & 0 & 6.8 & 0.26 & 0.42 & 1.7 & $\\dots$ \\\\\n    \t19 & blanco & 0 & 7.6 & 0.67 & 0.14 & 1.5 & $\\dots$ \\\\\n    \t20 & blanco & 0 & 6.6 & 0.27 & 0.41 & 1.3 & $\\dots$ \\\\\n    \t21 & blanco & 0 & 7.0 & 0.25 & 0.32 & 9.0 & $\\dots$ \\\\\n    \t22 & blanco & 0 & 6.9 & 0.24 & 0.35 & 1.0 & $\\dots$ \\\\\n    \t23 & blanco & 0 & 7.0 & 0.28 & 0.39 & 8.7 & $\\dots$ \\\\\n    \t24 & blanco & 0 & 7.4 & 0.27 & 0.48 & 1.1 & $\\dots$ \\\\\n    \t25 & blanco & 0 & 7.2 & 0.32 & 0.36 & 2.0 & $\\dots$ \\\\\n    \t26 & blanco & 0 & 8.5 & 0.24 & 0.39 & 10.4 & $\\dots$ \\\\\n    \t27 & blanco & 0 & 8.3 & 0.14 & 0.34 & 1.1 & $\\dots$ \\\\\n    \t28 & blanco & 0 & 7.4 & 0.25 & 0.36 & 2.05 & $\\dots$ \\\\\n    \t29 & blanco & 0 & 6.2 & 0.12 & 0.34 & 1.5 & $\\dots$ \\\\\n    \t30 & blanco & 0 & 5.8 & 0.27 & 0.2 & 14.95 & $\\dots$ \\\\\n    \t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Mostrar los tipos de cada variable del data frame.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n `schema` del paquete [`MLJ`](https://juliaai.github.io/MLJ.jl/).\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=25}\n    ``` {.julia .cell-code}\n    using MLJ\n    schema(df)\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    WARNING: using MLJ.fit! in module Main conflicts with an existing identifier.\n    WARNING: using MLJ.predict in module Main conflicts with an existing identifier.\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=26}\n    ```\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ names                ‚îÇ scitypes   ‚îÇ types   ‚îÇ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ tipo                 ‚îÇ Textual    ‚îÇ String7 ‚îÇ\n    ‚îÇ meses_barrica        ‚îÇ Count      ‚îÇ Int64   ‚îÇ\n    ‚îÇ acided_fija          ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ acided_volatil       ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ acido_citrico        ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ azucar_residual      ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ cloruro_sodico       ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ dioxido_azufre_libre ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ dioxido_azufre_total ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ densidad             ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ ph                   ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ sulfatos             ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ alcohol              ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n    ‚îÇ calidad              ‚îÇ Count      ‚îÇ Int64   ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Hacer un an√°lisis de los datos perdidos en el data frame.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=26}\n    ``` {.julia .cell-code}\n    describe(df, :nmissing)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=27}\n    ```{=tex}\n    \\begin{tabular}{r|cc}\n    \t& variable & nmissing\\\\\n    \t\\hline\n    \t& Symbol & Int64\\\\\n    \t\\hline\n    \t1 & tipo & 0 \\\\\n    \t2 & meses\\_barrica & 0 \\\\\n    \t3 & acided\\_fija & 0 \\\\\n    \t4 & acided\\_volatil & 0 \\\\\n    \t5 & acido\\_citrico & 0 \\\\\n    \t6 & azucar\\_residual & 0 \\\\\n    \t7 & cloruro\\_sodico & 0 \\\\\n    \t8 & dioxido\\_azufre\\_libre & 0 \\\\\n    \t9 & dioxido\\_azufre\\_total & 0 \\\\\n    \t10 & densidad & 0 \\\\\n    \t11 & ph & 0 \\\\\n    \t12 & sulfatos & 0 \\\\\n    \t13 & alcohol & 0 \\\\\n    \t14 & calidad & 0 \\\\\n    \\end{tabular}\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Mostrar la distribuci√≥n de frecuencias de las variables cuantitativas del data frame mediante histogramas.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=27}\n    ``` {.julia .cell-code}\n    using GLMakie\n    fig = Figure() \n    ax = [Axis(fig[trunc(Int, i / 3), i % 3], title = names(df)[i+2]) for i in 0:12]\n    for i in 1:13\n        hist!(ax[i], df[!, i+1], strokewidth = 0.5, strokecolor = (:white, 0.5))\n    end\n    fig\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=28}\n    ![](07-arboles-decision_files/figure-pdf/cell-28-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n    :::\n\na.  Se considera que un vino es bueno si tiene una puntuaci√≥n de calidad mayor que $6.5$. Recodificar la variable `calidad` en una variable categ√≥rica que tome el valor 1 si la calidad es mayor que $6.5$ y 0 en caso contrario.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=28}\n    ``` {.julia .cell-code}\n    using CategoricalArrays\n    # Recodificamos la variable calidad.\n    df.calidad = cut(df.calidad, [0, 6.5, 10], labels = [\" ‚òπÔ∏è \", \" üòä \"])\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=29}\n    ```\n    5320-element CategoricalArray{String,1,UInt32}:\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" üòä \"\n     \" ‚òπÔ∏è \"\n     \" üòä \"\n     \" ‚òπÔ∏è \"\n     ‚ãÆ\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Descomponer el data frame en un data frame con las variables predictivas y un vector con la variable objetivo `bueno`.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=29}\n    ``` {.julia .cell-code}\n    y, X = unpack(df, ==(:calidad), rng = 123)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=30}\n    ```\n    (CategoricalValue{String, UInt32}[\" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" üòä \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \"  ‚Ä¶  \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \"], 5320√ó13 DataFrame\n      Row ‚îÇ tipo     meses_barrica  acided_fija  acided_volatil  acido_citrico  az ‚ãØ\n          ‚îÇ String7  Int64          Float64      Float64         Float64        Fl ‚ãØ\n    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n        1 ‚îÇ blanco               0          6.7           0.5             0.36     ‚ãØ\n        2 ‚îÇ blanco               0          6.3           0.2             0.3\n        3 ‚îÇ blanco               0          6.2           0.35            0.03\n        4 ‚îÇ tinto                3          8.0           0.39            0.3\n        5 ‚îÇ blanco               0          7.9           0.255           0.26     ‚ãØ\n        6 ‚îÇ blanco               0          6.1           0.31            0.37\n        7 ‚îÇ blanco               0          6.8           0.28            0.36\n        8 ‚îÇ blanco               0          8.2           0.34            0.49\n        9 ‚îÇ tinto                0          6.7           0.48            0.02     ‚ãØ\n       10 ‚îÇ blanco               0          7.4           0.35            0.2\n       11 ‚îÇ tinto                5          7.5           0.53            0.06\n      ‚ãÆ   ‚îÇ    ‚ãÆ           ‚ãÆ             ‚ãÆ             ‚ãÆ               ‚ãÆ           ‚ã±\n     5311 ‚îÇ blanco               0          7.2           0.14            0.35\n     5312 ‚îÇ tinto                3          7.6           0.41            0.24     ‚ãØ\n     5313 ‚îÇ tinto                0          7.3           0.4             0.3\n     5314 ‚îÇ tinto                4          7.1           0.48            0.28\n     5315 ‚îÇ blanco               0          6.4           0.29            0.2\n     5316 ‚îÇ blanco               0          9.4           0.24            0.29     ‚ãØ\n     5317 ‚îÇ blanco               0          6.3           0.25            0.27\n     5318 ‚îÇ blanco               0          5.5           0.16            0.26\n     5319 ‚îÇ blanco               0          7.4           0.36            0.32\n     5320 ‚îÇ blanco               0          7.6           0.51            0.24     ‚ãØ\n                                                     8 columns and 5299 rows omitted)\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Para poder entrenar un modelo de un arbol de decisi√≥n, las variables predictivas deben ser cuantitativas. Transmformar las variables categ√≥ricas en variables num√©ricas.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=30}\n    ``` {.julia .cell-code}\n    # Convertir las variables categ√≥ricas a enteros.\n    coerce!(X, :tipo => OrderedFactor, :meses_barrica => Continuous)\n    schema(X)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=31}\n    ```\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ names                ‚îÇ scitypes         ‚îÇ types                             ‚îÇ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ tipo                 ‚îÇ OrderedFactor{2} ‚îÇ CategoricalValue{String7, UInt32} ‚îÇ\n    ‚îÇ meses_barrica        ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ acided_fija          ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ acided_volatil       ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ acido_citrico        ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ azucar_residual      ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ cloruro_sodico       ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ dioxido_azufre_libre ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ dioxido_azufre_total ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ densidad             ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ ph                   ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ sulfatos             ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îÇ alcohol              ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Definir un modelo de √°rbol de decisi√≥n con profundidad m√°xima 3.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Cargar el modelo `DecisionTreeClassifier` del paquete [`DecisionTree`](https://docs.juliahub.com/DecisionTree/) con la macros `@iload`.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=31}\n    ``` {.julia .cell-code}\n    # Cargamos el tipo de modelo.\n    Tree = @iload DecisionTreeClassifier pkg = \"DecisionTree\"\n    # Instanciamos el modelo con sus par√°metros.\n    arbol = Tree(max_depth =3, rng = 123)\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    [ Info: For silent loading, specify `verbosity=0`. \n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    import MLJDecisionTreeInterface ‚úî\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=32}\n    ```\n    DecisionTreeClassifier(\n      max_depth = 3, \n      min_samples_leaf = 1, \n      min_samples_split = 2, \n      min_purity_increase = 0.0, \n      n_subfeatures = 0, \n      post_prune = false, \n      merge_purity_threshold = 1.0, \n      display_depth = 5, \n      feature_importance = :impurity, \n      rng = 123)\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Evaluar el modelo tomando un 70% de ejemplos en el conjunto de entrenamiento y un 30% en el conjunto de test. Utilizar como m√©trica la precisi√≥n.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n [`evaluate`](https://juliaai.github.io/MLJ.jl/stable/evaluating_model_performance/#MLJBase.evaluate!) del paquete [`MLJ`](https://juliaai.github.io/MLJ.jl/) para evaluar el modelo. Los par√°metros m√°s importantes de esta funci√≥n son:\n\n    - `resampling`: Indica el m√©todo de muestreo para definir los conjuntos de entrenamiento y test. Los m√©todos m√°s habituales son:\n        - `Holdout(fraction_train = p)`: Divide el conjunto de datos tomando una proporci√≥n de $p$ ejemplos en el conjunto de entrenamiento y $1-p$ en el conjunto de test.\n        - `CV(nfolds = n, shuffle = true|false)`: Utiliza validaci√≥n cruzada con `n` iteraciones. Si se indica `shuffle = true`, se utiliza validaci√≥n cruzada aleatoria.\n        - `StratifiedCV(nfolds = n, shuffle = true|false)`: Utiliza validaci√≥n cruzada estratificada con `n` iteraciones. Si se indica `shuffle = true`, se utiliza validaci√≥n cruzada estratificada aleatoria.\n        - `InSample()`: Utiliza el conjunto de entrenamiento como conjunto de test.\n  \n    - `measures`: Indica las m√©tricas a utilizar para evaluar el modelo. Las m√©tricas m√°s habituales son:\n        - `cross_entropy`: P√©rdida de entrop√≠a cruzada.\n        - `confusion_matrix`: Matriz de confusi√≥n.\n        - `true_positive_rate`: Tasa de verdaderos positivos.\n        - `true_negative_rate`: Tasa de verdaderos negativos.\n        - `ppv`: Valor predictivo positivo.\n        - `npv`: Valor predictivo negativo.\n        - `accuracy`: Precisi√≥n.\n    \n        Se puede indicar m√°s de una en un vector.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=32}\n    ``` {.julia .cell-code}\n    evaluate(arbol, X, y, resampling = Holdout(fraction_train = 0.7, rng = 123), measures = accuracy)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=33}\n    ```\n    PerformanceEvaluation object with these fields:\n      model, measure, operation,\n      measurement, per_fold, per_observation,\n      fitted_params_per_fold, report_per_fold,\n      train_test_rows, resampling, repeats\n    Extract:\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ measure    ‚îÇ operation    ‚îÇ measurement ‚îÇ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n    ‚îÇ Accuracy() ‚îÇ predict_mode ‚îÇ 0.843       ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Evaluar el modelo mediante validaci√≥n cruzada estratificada usando las m√©tricas de la p√©rdida de entrop√≠a cruzada, la matriz de confusi√≥n, la tasa de verdaderos positivos, la tasa de verdaderos negativos, el valor predictivo positivo, el valor predictivo negativo y la precisi√≥n. ¬øEs un buen modelo?\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=33}\n    ``` {.julia .cell-code}\n    evaluate(arbol, X, y, resampling = StratifiedCV(rng = 123), measures = [cross_entropy, confusion_matrix, true_positive_rate, true_negative_rate, ppv, npv, accuracy])\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    \rEvaluating over 6 folds:  33%[========>                ]  ETA: 0:00:02\rEvaluating over 6 folds: 100%[=========================] Time: 0:00:01\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=34}\n    ```\n    PerformanceEvaluation object with these fields:\n      model, measure, operation,\n      measurement, per_fold, per_observation,\n      fitted_params_per_fold, report_per_fold,\n      train_test_rows, resampling, repeats\n    Extract:\n    ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    ‚îÇ   ‚îÇ measure                  ‚îÇ operation    ‚îÇ measurement                    ‚ãØ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    ‚îÇ A ‚îÇ LogLoss(                 ‚îÇ predict      ‚îÇ 0.375                          ‚ãØ\n    ‚îÇ   ‚îÇ   tol = 2.22045e-16)     ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ B ‚îÇ ConfusionMatrix(         ‚îÇ predict_mode ‚îÇ ConfusionMatrix{2}([3821534 78 ‚ãØ\n    ‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   perm = nothing,        ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ C ‚îÇ TruePositiveRate(        ‚îÇ predict_mode ‚îÇ 0.128                          ‚ãØ\n    ‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ D ‚îÇ TrueNegativeRate(        ‚îÇ predict_mode ‚îÇ 1.0                            ‚ãØ\n    ‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ E ‚îÇ PositivePredictiveValue( ‚îÇ predict_mode ‚îÇ 0.994                          ‚ãØ\n    ‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ F ‚îÇ NegativePredictiveValue( ‚îÇ predict_mode ‚îÇ 0.83                           ‚ãØ\n    ‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n    ‚îÇ ‚ãÆ ‚îÇ            ‚ãÆ             ‚îÇ      ‚ãÆ       ‚îÇ                        ‚ãÆ       ‚ã±\n    ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                                         1 column and 2 rows omitted\n    ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    ‚îÇ   ‚îÇ per_fold                                                                 ‚ãØ\n    ‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    ‚îÇ A ‚îÇ [0.391, 0.394, 0.35, 0.358, 0.365, 0.391]                                ‚ãØ\n    ‚îÇ B ‚îÇ ConfusionMatrix{2, true, CategoricalValue{String, UInt32}}[ConfusionMatr ‚ãØ\n    ‚îÇ C ‚îÇ [0.125, 0.167, 0.155, 0.112, 0.113, 0.0952]                              ‚ãØ\n    ‚îÇ D ‚îÇ [1.0, 0.999, 1.0, 1.0, 1.0, 1.0]                                         ‚ãØ\n    ‚îÇ E ‚îÇ [1.0, 0.966, 1.0, 1.0, 1.0, 1.0]                                         ‚ãØ\n    ‚îÇ F ‚îÇ [0.83, 0.837, 0.835, 0.827, 0.828, 0.825]                                ‚ãØ\n    ‚îÇ G ‚îÇ [0.834, 0.841, 0.84, 0.831, 0.832, 0.828]                                ‚ãØ\n    ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                                                   2 columns omitted\n    ```\n    :::\n    :::\n    \n    \n    La precisi√≥n del modelo es de $0.834$ que no est√° mal, pero si consdieramos la tasa de verdadero positivos, que es $0.13$ y la tasa de verdaderos negativos, que es pr√°cticamente 1, el modelo tiene un buen rendimiento en la clasificaci√≥n de los vinos malos, pero un mal rendimiento en la clasificaci√≥n de los vinos buenos. Por lo tanto, no podemos decir que sea un buen modelo.\n    :::\n\na.  Construir √°rboles de decisi√≥n con profundidades m√°ximas de 2 a 10 y evaluar el modelo con validaci√≥n cruzada estratificada. ¬øCu√°l es la profundidad m√°xima que da mejor resultado?\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n [`TunedModel`](https://juliaai.github.io/MLJ.jl/stable/tuning_models/#MLJTuning.TunedModel) del paquete [`MLJ`](https://juliaai.github.io/MLJ.jl/) para ajustar los par√°metros del modelo.\n\n    Los par√°metros m√°s importantes de esta funci√≥n son:\n    - `model`: Indica el modelo a ajustar.\n    - `resampling`: Indica el m√©todo de muestreo para definir los conjuntos de entrenamiento y test.\n    - `tuning`: Indica el m√©todo de ajuste de los par√°metros del modelo. Los m√©todos m√°s habituales son:\n        - `Grid(resolution = n)`: Ajusta los par√°metros del modelo utilizando una cuadr√≠cula de b√∫squeda con `n` valores.\n        - `RandomSearch(resolution = n)`: Ajusta los par√°metros del modelo utilizando una b√∫squeda aleatoria con `n` valores.\n    - range: Indica el rango de valores a utilizar para ajustar los par√°metros del modelo. Se puede indicar un rango de valores o un vector de valores.\n    - `measure`: Indica la m√©trica a utilizar para evaluar el modelo.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=34}\n    ``` {.julia .cell-code}\n    # Instanciamos el modelo de √°rbol de decisi√≥n.\n    arbol = Tree()\n    # Definimos el rango de valores a utilizar para ajustar los par√°metros del modelo.\n    r = range(arbol, :max_depth, lower=2, upper=10)\n    # Ajustamos los par√°metros del modelo utilizando una cuadr√≠cula de b√∫squeda con 9 valores.\n    arbol_parametrizado = TunedModel(\n        model = arbol,\n        resampling = StratifiedCV(rng = 123),\n        tuning = Grid(resolution = 9),\n        range = r,\n        measure = accuracy)\n    # Definimos una m√°quina de aprendizaje con el modelo, las variables predictivas y la variable objetivo.\n    mach = machine(arbol_parametrizado, X, y)\n    # Ajustamos los par√°metros del modelo.\n    MLJ.fit!(mach)\n    # Mostramos los par√°metros del mejor modelo.\n    fitted_params(mach).best_model\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    [ Info: Training machine(ProbabilisticTunedModel(model = DecisionTreeClassifier(max_depth = -1, ‚Ä¶), ‚Ä¶), ‚Ä¶).\n    [ Info: Attempting to evaluate 9 models.\n    \rEvaluating over 9 metamodels:  22%[=====>                   ]  ETA: 0:00:03\rEvaluating over 9 metamodels:  33%[========>                ]  ETA: 0:00:02\rEvaluating over 9 metamodels:  44%[===========>             ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  56%[=============>           ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  67%[================>        ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  78%[===================>     ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  89%[======================>  ]  ETA: 0:00:00\rEvaluating over 9 metamodels: 100%[=========================] Time: 0:00:02\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=35}\n    ```\n    DecisionTreeClassifier(\n      max_depth = 5, \n      min_samples_leaf = 1, \n      min_samples_split = 2, \n      min_purity_increase = 0.0, \n      n_subfeatures = 0, \n      post_prune = false, \n      merge_purity_threshold = 1.0, \n      display_depth = 5, \n      feature_importance = :impurity, \n      rng = TaskLocalRNG())\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Dibujar la curva de aprendizaje del modelo en funci√≥n de la profundidad del √°rbol de decisi√≥n.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n [`learning_curve`](https://juliaai.github.io/MLJ.jl/stable/learning_curves/#MLJBase.learning_curve) del paquete [`MLJ`](https://juliaai.github.io/MLJ.jl/) para dibujar la curva de aprendizaje.\n    Los par√°metros m√°s importantes de esta funci√≥n son:\n    - `mach`: Indica la m√°quina de aprendizaje a utilizar.\n    - `range`: Indica el rango de valores a utilizar para ajustar los par√°metros del modelo.\n    - `resampling`: Indica el m√©todo de muestreo para definir los conjuntos de entrenamiento y test.\n    - `measure`: Indica la m√©trica a utilizar para evaluar el modelo.\n    - `rngs`: Indica la semilla para la generaci√≥n de n√∫meros aleatorios. Se pueden indicar varias semillas en un vector y se genera una curva de aprendizaje para cada semilla.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=35}\n    ``` {.julia .cell-code}\n    # Instanciamos el modelo de √°rbol de decisi√≥n.\n    arbol = Tree()\n    # Definimos una m√°quina de aprendizaje con el modelo, las variables predictivas y la variable objetivo.\n    mach = machine(arbol, X, y)\n    # Definimos el rango de valores a utilizar para ajustar los par√°metros del modelo.\n    r = range(arbol, :max_depth, lower=2, upper=10)\n    # Dibujamos la curva de aprendizaje.\n    curva = learning_curve(mach, range = r, resampling = StratifiedCV(rng = 123), measure = accuracy)\n    # Dibujamos la curva de aprendizaje.\n    fig = Figure()\n    ax = Axis(fig[1, 1], title = \"Curva de aprendizaje\", xlabel = \"Profundidad del √°rbol\", ylabel = \"Precisi√≥n\")\n    Makie.scatter!(ax, curva.parameter_values, curva.measurements)\n    fig\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    [ Info: Training machine(ProbabilisticTunedModel(model = DecisionTreeClassifier(max_depth = -1, ‚Ä¶), ‚Ä¶), ‚Ä¶).\n    [ Info: Attempting to evaluate 9 models.\n    \rEvaluating over 9 metamodels:  22%[=====>                   ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  33%[========>                ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  44%[===========>             ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  56%[=============>           ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  67%[================>        ]  ETA: 0:00:01\rEvaluating over 9 metamodels:  78%[===================>     ]  ETA: 0:00:00\rEvaluating over 9 metamodels:  89%[======================>  ]  ETA: 0:00:00\rEvaluating over 9 metamodels: 100%[=========================] Time: 0:00:01\n    ‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n    ‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=36}\n    ![](07-arboles-decision_files/figure-pdf/cell-36-output-2.png){fig-pos='H'}\n    :::\n    :::\n    \n    \n    :::\n\na.  Construir un √°rbol de decisi√≥n con la profundidad m√°xima que da mejor resultado y visualizarlo.\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=36}\n    ``` {.julia .cell-code}\n    # Instanciamos el modelo de √°rbol de decisi√≥n.\n    arbol = Tree(max_depth = 4)\n    # Definimos una m√°quina de aprendizaje con el modelo, las variables predictivas y la variable objetivo.\n    mach = machine(arbol, X, y)\n    # Ajustamos los par√°metros del modelo.\n    MLJ.fit!(mach)\n    # Visualizamos el √°rbol de decisi√≥n.\n    fitted_params(mach).tree\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    [ Info: Training machine(DecisionTreeClassifier(max_depth = 4, ‚Ä¶), ‚Ä¶).\n    ```\n    :::\n    \n    ::: {.cell-output .cell-output-display execution_count=37}\n    ```\n    alcohol < 10.62\n    ‚îú‚îÄ meses_barrica < 8.5\n    ‚îÇ  ‚îú‚îÄ acided_volatil < 0.3125\n    ‚îÇ  ‚îÇ  ‚îú‚îÄ acided_volatil < 0.2025\n    ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ  ‚òπÔ∏è  (408/496)\n    ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ  ‚òπÔ∏è  (1095/1172)\n    ‚îÇ  ‚îÇ  ‚îî‚îÄ meses_barrica < 5.5\n    ‚îÇ  ‚îÇ     ‚îú‚îÄ  ‚òπÔ∏è  (1334/1345)\n    ‚îÇ  ‚îÇ     ‚îî‚îÄ  ‚òπÔ∏è  (51/58)\n    ‚îÇ  ‚îî‚îÄ  üòä  (25/25)\n    ‚îî‚îÄ meses_barrica < 12.5\n       ‚îú‚îÄ cloruro_sodico < 0.0455\n       ‚îÇ  ‚îú‚îÄ alcohol < 12.55\n       ‚îÇ  ‚îÇ  ‚îú‚îÄ  ‚òπÔ∏è  (751/1160)\n       ‚îÇ  ‚îÇ  ‚îî‚îÄ  üòä  (185/286)\n       ‚îÇ  ‚îî‚îÄ meses_barrica < 10.5\n       ‚îÇ     ‚îú‚îÄ  ‚òπÔ∏è  (552/629)\n       ‚îÇ     ‚îî‚îÄ  üòä  (25/43)\n       ‚îî‚îÄ alcohol < 14.45\n          ‚îú‚îÄ  üòä  (105/105)\n          ‚îî‚îÄ  ‚òπÔ∏è  (1/1)\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  ¬øCu√°l es la importancia de cada variable en el modelo?\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n `feature_importances` del paquete [`DecisionTree`](https://juliaai.github.io/DecisionTree.jl/) para calcular la importancia de cada variable.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n\n    ::: {.cell execution_count=37}\n    ``` {.julia .cell-code}\n    # Calculamos la importancia de cada variable.\n    feature_importances(mach)\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=38}\n    ```\n    13-element Vector{Pair{Symbol, Float64}}:\n                  :alcohol => 0.5303315899204789\n            :meses_barrica => 0.26854115615561525\n           :acided_volatil => 0.1040970236546446\n           :cloruro_sodico => 0.09703023026926123\n                     :tipo => 0.0\n              :acided_fija => 0.0\n            :acido_citrico => 0.0\n          :azucar_residual => 0.0\n     :dioxido_azufre_libre => 0.0\n     :dioxido_azufre_total => 0.0\n                 :densidad => 0.0\n                       :ph => 0.0\n                 :sulfatos => 0.0\n    ```\n    :::\n    :::\n    \n    \n    :::\n\na.  Predecir la calidad de los 10 primeros vinos del conjunto de ejemplos.\n\n    :::{.callout-note collapse=\"true\"}\n    ## Ayuda\n    Usar la funci√≥n `predict` del paquete [`DecisionTree`](https://juliaai.github.io/DecisionTree.jl/) para predecir las probabilidades de pertenecer a cada clase un ejemplo o conjunto de ejemplos.\n\n    Usar la funci√≥n `predict_mode` del paquete [`DecisionTree`](https://juliaai.github.io/DecisionTree.jl/) para predecir la clase de un ejemplo o conjunto de ejemplos.\n    :::\n\n    :::{.callout-tip collapse=\"true\"}\n    ## Soluci√≥n\n\n    Primero calculamos las probabilidades de cada clase.\n\n\n    ::: {.cell execution_count=38}\n    ``` {.julia .cell-code}\n    MLJ.predict(mach, X[1:10, :])\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=39}\n    ```\n    10-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt32, Float64}:\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.992,  üòä =>0.00818)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.823,  üòä =>0.177)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.992,  üòä =>0.00818)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.992,  üòä =>0.00818)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.647,  üòä =>0.353)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.647,  üòä =>0.353)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.647,  üòä =>0.353)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.878,  üòä =>0.122)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.992,  üòä =>0.00818)\n     UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =>0.992,  üòä =>0.00818)\n    ```\n    :::\n    :::\n    \n    \n    Y ahora predecimos la clase.\n\n\n    ::: {.cell execution_count=39}\n    ``` {.julia .cell-code}\n    predict_mode(mach, X[1:10, :])\n    ```\n    \n    ::: {.cell-output .cell-output-display execution_count=40}\n    ```\n    10-element CategoricalArray{String,1,UInt32}:\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n     \" ‚òπÔ∏è \"\n    ```\n    :::\n    :::\n    \n    \n    :::\n:::\n\n",
    "supporting": [
      "07-arboles-decision_files/figure-pdf"
    ],
    "filters": []
  }
}