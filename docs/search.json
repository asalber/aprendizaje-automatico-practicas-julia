[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "P√°cticas de Aprendizaje Autom√°tico con Julia",
    "section": "",
    "text": "Prefacio\n¬°Bienvenido a Pr√°cticas de Aprendizaje Autom√°tico con Julia!\nEste libro presenta una recopilaci√≥n de pr√°cticas de Aprendizaje Autom√°tico (Machine Learning) con el lenguaje de programaci√≥n Julia.\nNo es un libro para aprender a programar con Julia, ya que solo ense√±a el uso del lenguaje y de algunos de sus paquetes para implementar los algoritmos m√°s comunes de Aprendizaje Autom√°tico. Para quienes est√©n interesados en aprender a programar en este Julia, os recomiendo leer este manual de Julia.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "P√°cticas de Aprendizaje Autom√°tico con Julia",
    "section": "Licencia",
    "text": "Licencia\nEsta obra est√° bajo una licencia Reconocimiento ‚Äì No comercial ‚Äì Compartir bajo la misma licencia 3.0 Espa√±a de Creative Commons. Para ver una copia de esta licencia, visite https://creativecommons.org/licenses/by-nc-sa/3.0/es/.\nCon esta licencia eres libre de:\n\nCopiar, distribuir y mostrar este trabajo.\nRealizar modificaciones de este trabajo.\n\nBajo las siguientes condiciones:\n\nReconocimiento. Debe reconocer los cr√©ditos de la obra de la manera especificada por el autor o el licenciador (pero no de una manera que sugiera que tiene su apoyo o apoyan el uso que hace de su obra).\nNo comercial. No puede utilizar esta obra para fines comerciales.\nCompartir bajo la misma licencia. Si altera o transforma esta obra, o genera una obra derivada, s√≥lo puede distribuir la obra generada bajo una licencia id√©ntica a √©sta.\n\nAl reutilizar o distribuir la obra, tiene que dejar bien claro los t√©rminos de la licencia de esta obra.\nEstas condiciones pueden no aplicarse si se obtiene el permiso del titular de los derechos de autor.\nNada en esta licencia menoscaba o restringe los derechos morales del autor.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "1.1 El REPL de Julia\nLa gran potencia de c√°lculo alcanzada por los ordenadores en las √∫ltimas d√©cadas ha convertido a los mismos en poderosas herramientas al servicio de todas aquellas disciplinas que, como las matem√°ticas, requieren c√°lculos largos y complejos.\nJulia es un lenguaje de programaci√≥n especialmente orientado al c√°lculo num√©rico y el an√°lisis de datos. Julia permite adem√°s realizar c√°lculos simb√≥licos y dispone de una gran biblioteca de paquetes con aplicaciones en muy diversas √°reas de las Matem√°ticas como C√°lculo, √Ålgebra, Geometr√≠a, Matem√°tica Discreta o Estad√≠stica.\nLa ventaja de Julia frente a otros programas habituales de c√°lculo como Mathematica, MATLAB o Sage radica en su potencia de c√°lculo y su velocidad (equiparable al lenguaje C), lo que lo hace ideal para manejar grandes vol√∫menes de datos o realizar tareas que requieran largos y complejos c√°lculos. Adem√°s, es software libre por lo que resulta ideal para introducirlo en el aula como soporte computacional para los modelos matem√°ticos sin coste alguno.\nEn el siguiente enlace se explica el procedimiento de instalaci√≥n de Julia.\nExisten tambi√©n varios entornos de desarrollo online que permiten ejecutar c√≥digo en Julia sin necesidad de instalarlo en nuestro ordenador, como por ejemplo Replit, Cocalc o Codeanywhere.\nEl objetivo de esta pr√°ctica es introducir al alumno en la utilizaci√≥n de este lenguaje, ense√±√°ndole a realizar las operaciones b√°sicas m√°s habituales en C√°lculo.\nPara arrancar el REPL^(REPL es el acr√≥nimo de Read, Evaluate, Print and Loop, que describe el funcionamiento del compilador de Julia) de julia basta con abrir una terminal y teclear julia.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#el-repl-de-julia",
    "href": "01-introduccion.html#el-repl-de-julia",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "prompt&gt; julia\n               _\n   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.7.3 (2022-05-06)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org/ release\n|__/                   |\n\njulia&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#el-gestor-de-paquetes-de-julia",
    "href": "01-introduccion.html#el-gestor-de-paquetes-de-julia",
    "title": "1¬† Introducci√≥n",
    "section": "1.2 El gestor de paquetes de Julia",
    "text": "1.2 El gestor de paquetes de Julia\nJulia viene con varios paquetes b√°sicos preinstalados, como por ejemplo el paquete LinearAlgebra que define funciones b√°sicas del √Ålgebra Lineal, pero en estas pr√°cticas utilizaremos otros muchos paquetes que a√±aden m√°s funcionalidades que no vienen instalados por defecto y tendremos que instalarlos aparte. Julia tiene un potente gestor de paquetes que facilita la b√∫squeda, instalaci√≥n, actualizaci√≥n y eliminaci√≥n de paquetes.\nPor defecto el gestor de paquetes utiliza el repositorio de paquetes oficial pero se pueden instalar paquetes de otros repositorios.\nPara entrar en el modo de gesti√≥n de paquetes hay que teclear ]. Esto produce un cambio en el prompt del REPL de Julia.\nLos comandos m√°s habituales son:\n\nadd p: Instala el paquete p en el entorno activo de Julia.\nupdate: Actualiza los paquetes del entorno activo de Julia.\nstatus: Muestra los paquetes instalados y sus versiones en el entorno activo de Julia.\nremove p: Elimina el paquete p del entorno activo de Julia.\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nPara instalar el paquete SymPy para c√°lculo simb√≥lico basta con teclear add Sympy.\n(@v1.7) pkg&gt; add SymPy\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.7/Project.toml`\n  [24249f21] + SymPy v1.1.6\n    Updating `~/.julia/environments/v1.7/Manifest.toml`\n  [3709ef60] + CommonEq v0.2.0\n  [38540f10] + CommonSolve v0.2.1\n  [438e738f] + PyCall v1.93.1\n  [24249f21] + SymPy v1.1.6",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#operadores-aritm√©ticos.",
    "href": "01-introduccion.html#operadores-aritm√©ticos.",
    "title": "1¬† Introducci√≥n",
    "section": "1.3 Operadores aritm√©ticos.",
    "text": "1.3 Operadores aritm√©ticos.\nEl uso m√°s simple de Julia es la realizaci√≥n de operaciones aritm√©ticas como en una calculadora. En Julia se utilizan los siguientes operadores.\n\n\n\nOperador\nDescripci√≥n\n\n\n\n\nx + y\nSuma\n\n\nx - y\nResta\n\n\nx * y\nProducto\n\n\nx / y\nDivisi√≥n\n\n\nx √∑ y\nCociente divisi√≥n entera\n\n\nx % y\nResto divisi√≥n entera\n\n\nx ^ y\nPotencia",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#operadores-de-comparaci√≥n",
    "href": "01-introduccion.html#operadores-de-comparaci√≥n",
    "title": "1¬† Introducci√≥n",
    "section": "1.4 Operadores de comparaci√≥n",
    "text": "1.4 Operadores de comparaci√≥n\n\n\n\nOperador\nDescripci√≥n\n\n\n\n\n==\nIgualdad\n\n\n!=, ‚â†\nDesigualdad\n\n\n&lt;\nMenor que\n\n\n&lt;=, ‚â§\nMenor o igual que\n\n\n&gt;\nMayor que\n\n\n&gt;=, ‚â•\nMayor o igual que",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#operadores-booleanos",
    "href": "01-introduccion.html#operadores-booleanos",
    "title": "1¬† Introducci√≥n",
    "section": "1.5 Operadores booleanos",
    "text": "1.5 Operadores booleanos\n\n\n\nOperador\nDescripci√≥n\n\n\n\n\n!x\nNegaci√≥n\n\n\nx && y\nConjunci√≥n (y)\n\n\nx || y\nDisyunci√≥n (o)\n\n\n\nExisten tambi√©n un mont√≥n de funciones predefinidas habituales en C√°lculo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#funciones-de-redondeo",
    "href": "01-introduccion.html#funciones-de-redondeo",
    "title": "1¬† Introducci√≥n",
    "section": "1.6 Funciones de redondeo",
    "text": "1.6 Funciones de redondeo\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\nround(x)\nDevuelve el entero m√°s pr√≥ximo a x\n\n\nround(x, digits = n)\nDevuelve al valor m√°s pr√≥ximo a x con n decimales\n\n\nfloor(x)\nRedondea x al pr√≥ximo entero menor\n\n\nceil(x)\nRedondea x al pr√≥ximo entero mayor\n\n\ntrunc(x)\nDevuelve la parte entera de x\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; round(2.7)\n3.0\n\njulia&gt; floor(2.7)\n2.0\n\njulia&gt; floor(-2.7)\n-3.0\n\njulia&gt; ceil(2.7)\n3.0\n\njulia&gt; ceil(-2.7)\n-2.0\n\njulia&gt; trunc(2.7)\n2.0\n\njulia&gt; trunc(-2.7)\n-2.0\n\njulia&gt; round(2.5)\n2.0\n\njulia&gt; round(2.786, digits = 2)\n2.79",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#funciones-de-divisi√≥n",
    "href": "01-introduccion.html#funciones-de-divisi√≥n",
    "title": "1¬† Introducci√≥n",
    "section": "1.7 Funciones de divisi√≥n",
    "text": "1.7 Funciones de divisi√≥n\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\ndiv(x,y), x√∑y\nCociente de la divisi√≥n entera\n\n\nfld(x,y)\nCociente de la divisi√≥n entera redondeado hacia abajo\n\n\ncld(x,y)\nCociente de la divisi√≥n entera redondeado hacia arriba\n\n\nrem(x,y), x%y\nResto de la divisi√≥n entera. Se cumple x == div(x,y)*y + rem(x,y)\n\n\nmod(x,y)\nM√≥dulo con respecto a y. Se cumple x == fld(x,y)*y + mod(x,y)\n\n\ngcd(x,y...)\nM√°ximo com√∫n divisor positivo de x, y,‚Ä¶\n\n\nlcm(x,y...)\nM√≠nimo com√∫n m√∫ltiplo positivo de x, y,‚Ä¶\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; div(5,3)\n1\n\njulia&gt; cld(5,3)\n2\n\njulia&gt; 5%3\n2\n\njulia&gt; -5%3\n-2\n\njulia&gt; mod(5,3)\n2\n\njulia&gt; mod(-5,3)\n1\n\njulia&gt; gcd(12,18)\n6\n\njulia&gt; lcm(12,18)\n36",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#funciones-para-el-signo-y-el-valor-absoluto",
    "href": "01-introduccion.html#funciones-para-el-signo-y-el-valor-absoluto",
    "title": "1¬† Introducci√≥n",
    "section": "1.8 Funciones para el signo y el valor absoluto",
    "text": "1.8 Funciones para el signo y el valor absoluto\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\nabs(x)\nValor absoluto de x\n\n\nsign(x)\nDevuelve -1 si x es positivo, -1 si es negativo y 0 si es 0.\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; abs(2.5)\n2.5\n\njulia&gt; abs(-2.5)\n2.5\n\njulia&gt; sign(-2.5)\n-1.0\n\njulia&gt; sign(0)\n0\n\njulia&gt; sign(2.5)\n1.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#ra√≠ces-exponenciales-y-logaritmos",
    "href": "01-introduccion.html#ra√≠ces-exponenciales-y-logaritmos",
    "title": "1¬† Introducci√≥n",
    "section": "1.9 Ra√≠ces, exponenciales y logaritmos",
    "text": "1.9 Ra√≠ces, exponenciales y logaritmos\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\nsqrt(x), ‚àöx\nRa√≠z cuadrada de x\n\n\ncbrt(x), ‚àõx\nRa√≠z c√∫bica de x\n\n\nexp(x)\nExponencial de x\n\n\nlog(x)\nLogaritmo neperiano de x\n\n\nlog(b,x)\nLogaritmo en base b de x\n\n\nlog2(x)\nLogaritmo en base 2 de x\n\n\nlog10(x)\nLogaritmo en base 10 de x\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; sqrt(4)\n2.0\n\njulia&gt; cbrt(27)\n3.0\n\njulia&gt; exp(1)\n2.718281828459045\n\njulia&gt; exp(-Inf)\n0.0\n\njulia&gt; log(1)\n0.0\n\njulia&gt; log(0)\n-Inf\n\njulia&gt; log(-1)\nERROR: DomainError with -1.0:\nlog will only return a complex result if called with a complex argument.\n...\n\njulia&gt; log(-1+0im)\n0.0 + 3.141592653589793im\n\njulia&gt; log2(2^3)\n3.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#funciones-trigonom√©tricas",
    "href": "01-introduccion.html#funciones-trigonom√©tricas",
    "title": "1¬† Introducci√≥n",
    "section": "1.10 Funciones trigonom√©tricas",
    "text": "1.10 Funciones trigonom√©tricas\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\nhypot(x,y)\nHipotenusa del tri√°ngulo rect√°ngulo con catetos x e y\n\n\nsin(x)\nSeno del √°ngulo x en radianes\n\n\nsind(x)\nSeno del √°ngulo x en grados\n\n\ncos(x)\nCoseno del √°ngulo x en radianes\n\n\ncosd(x)\nCoseno del √°ngulo x en grados\n\n\ntan(x)\nTangente del √°ngulo x en radianes\n\n\ntand(x)\nTangente del √°ngulo x en grados\n\n\nsec(x)\nSecante del √°ngulo x en radianes\n\n\ncsc(x)\nCosecante del √°ngulo x en radianes\n\n\ncot(x)\nCotangente del √°ngulo x en radianes\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; sin(œÄ/2)\n1.0\n\njulia&gt; cos(œÄ/2)\n6.123233995736766e-17\n\njulia&gt; cosd(90)\n0.0\n\njulia&gt; tan(œÄ/4)\n0.9999999999999999\n\njulia&gt; tand(45)\n1.0\n\njulia&gt; tan(œÄ/2)\n1.633123935319537e16\n\njulia&gt; tand(90)\nInf\n\njulia&gt; sin(œÄ/4)^2 + cos(œÄ/4)^2\n1.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#funciones-trigonom√©tricas-inversas",
    "href": "01-introduccion.html#funciones-trigonom√©tricas-inversas",
    "title": "1¬† Introducci√≥n",
    "section": "1.11 Funciones trigonom√©tricas inversas",
    "text": "1.11 Funciones trigonom√©tricas inversas\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\nasin(x)\nArcoseno (inversa del seno) de x en radianes\n\n\nasind(x)\nArcoseno (inversa del seno) de x en grados\n\n\nacos(x)\nArcocoseno (inversa del coseno) de x en radianes\n\n\nacosd(x)\nArcocoseno (inversa del coseno) de x en grados\n\n\natan(x)\nArcotangente (inversa de la tangente) de x en radianes\n\n\natand(x)\nArcotangente (inversa de la tangente) de x en grados\n\n\nasec(x)\nArcosecante (inversa de la secante) de x en radianes\n\n\nacsc(x)\nArcocosecante (inversa de la cosecante) de x en radianes\n\n\nacot(x)\nArcocotangente (inversa de la cotangente) de x en radianes\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; asin(1)\n1.5707963267948966\n\njulia&gt; asind(1)\n90.0\n\njulia&gt; acos(-1)\n3.141592653589793\n\njulia&gt; atan(1)\n0.7853981633974483\n\njulia&gt; atand(tan(œÄ/4))\n45.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#precedencia-de-operadores",
    "href": "01-introduccion.html#precedencia-de-operadores",
    "title": "1¬† Introducci√≥n",
    "section": "1.12 Precedencia de operadores",
    "text": "1.12 Precedencia de operadores\nA la hora de evaluar una expresi√≥n aritm√©tica, Julia eval√∫a los operadores seg√∫n el siguiente orden de prioridad (de mayor a menor prioridad).\n\n\n\n\n\n\n\n\nCategor√≠a\nOperadores\nAsociatividad\n\n\n\n\nFunciones\nexp, log, sin, etc.\n\n\n\nExponenciaci√≥n\n^\nDerecha\n\n\nUnarios\n+ - ‚àö\nDerecha\n\n\nFracciones\n//\nIzquierda\n\n\nMultiplicaci√≥n\n* / % & \\ √∑\nIzquierda\n\n\nAdici√≥n\n+ - |\nIzquierda\n\n\nComparaciones\n&gt; &lt; &gt;= &lt;= == != !==\n\n\n\nAsignaciones\n= += -= *= /= //= ^= √∑= %= |= &=\nDerecha\n\n\n\nCuando se quiera evaluar un operador con menor prioridad antes que otro con mayor prioridad, hay que utilizar par√©ntesis.\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\njulia&gt; 1 + 4 ^ 2 / 2 - 3\n6.0\n\njulia&gt; (1 + 4 ^ 2) / 2 - 3\n5.5\n\njulia&gt; (1 + 4) ^ 2 / 2 - 3\n9.5\n\njulia&gt; 1 + 4 ^ 2 / (2 - 3)\n-15.0\n\njulia&gt; (1 + 4 ^ 2) / (2 - 3)\n-17.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#definici√≥n-de-variables",
    "href": "01-introduccion.html#definici√≥n-de-variables",
    "title": "1¬† Introducci√≥n",
    "section": "1.13 Definici√≥n de variables",
    "text": "1.13 Definici√≥n de variables\nPara definir variables se pueden utilizar cualquier car√°cter Unicode. Los nombres de las variables pueden contener m√°s de una letra y, en tal caso, pueden usarse tambi√©n n√∫meros, pero siempre debe comenzar por una letra. As√≠, para Julia, la expresi√≥n xy, no se interpreta como el producto de la variable \\(x\\) por la variable \\(y\\), sino como la variable \\(xy\\). Adem√°s, se distingue entre may√∫sculas y min√∫sculas, as√≠ que no es lo mismo \\(xy\\) que \\(xY\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "02-preprocesamiento.html",
    "href": "02-preprocesamiento.html",
    "title": "2¬† Preprocesamiento de datos",
    "section": "",
    "text": "2.1 Ejercicios Resueltos\nEsta pr√°ctica contiene ejercicios que muestran como preprocesar un conjunto de datos con Julia. El preprocesamiento de datos es una tarea fundamental en la construcci√≥n de modelos de aprendizaje autom√°tico que consiste en la limpieza, transformaci√≥n y preparaci√≥n de los datos para que puedan alimentar el proceso de entrenamiento de los modelos, as√≠ como para la evaluaci√≥n de su rendimiento. El preprocesamiento de datos incluye tareas como\nPara la realizaci√≥n de esta pr√°ctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preprocesamiento de datos</span>"
    ]
  },
  {
    "objectID": "02-preprocesamiento.html#ejercicios-resueltos",
    "href": "02-preprocesamiento.html#ejercicios-resueltos",
    "title": "2¬† Preprocesamiento de datos",
    "section": "",
    "text": "using CSV  # Para la lectura de archivos CSV.\nusing DataFrames  # Para el manejo de datos tabulares.\nusing PrettyTables  # Para mostrar tablas formateadas.\nusing Plots  # Para el dibujo de gr√°ficas.\nusing Makie  # Para obtener gr√°ficos interactivos.\n\nEjercicio 2.1 La siguiente tabla contiene los ingresos y gastos de una empresa durante el primer trimestre del a√±o.\n\nCrear un data frame con los datos de la tabla.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n DataFrame del paquete DataFrames para partir el rango de valores en intervalos y asociar a cada intervalo una categor√≠a.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing DataFrames\ndf = DataFrame(\n    Mes = [\"Enero\", \"Febrero\", \"Marzo\", \"Abril\"],\n    Ingresos = [45000, 41500, 51200, 49700],\n    Gastos = [33400, 35400, 35600, 36300],\n    Impuestos = [6450, 6300, 7100, 6850]\n    )\n\n4√ó4 DataFrame\n\n\n\nRow\nMes\nIngresos\nGastos\nImpuestos\n\n\n\nString\nInt64\nInt64\nInt64\n\n\n\n\n1\nEnero\n45000\n33400\n6450\n\n\n2\nFebrero\n41500\n35400\n6300\n\n\n3\nMarzo\n51200\n35600\n7100\n\n\n4\nAbril\n49700\n36300\n6850\n\n\n\n\n\n\n\n\n\nCrear una nueva columna con los beneficios de cada mes (ingresos - gastos - impuestos).\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf.Beneficios = df.Ingresos - df.Gastos - df.Impuestos\ndf\n\n4√ó5 DataFrame\n\n\n\nRow\nMes\nIngresos\nGastos\nImpuestos\nBeneficios\n\n\n\nString\nInt64\nInt64\nInt64\nInt64\n\n\n\n\n1\nEnero\n45000\n33400\n6450\n5150\n\n\n2\nFebrero\n41500\n35400\n6300\n-200\n\n\n3\nMarzo\n51200\n35600\n7100\n8500\n\n\n4\nAbril\n49700\n36300\n6850\n6550\n\n\n\n\n\n\n\n\n\nCrear una nueva columna con el factor Balance con dos posibles categor√≠as: positivo si ha habido beneficios y negativo si ha habido p√©rdidas.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf.Balance = ifelse.(df.Beneficios .&gt; 0, \"positivo\", \"negativo\")\ndf\n\n4√ó6 DataFrame\n\n\n\nRow\nMes\nIngresos\nGastos\nImpuestos\nBeneficios\nBalance\n\n\n\nString\nInt64\nInt64\nInt64\nInt64\nString\n\n\n\n\n1\nEnero\n45000\n33400\n6450\n5150\npositivo\n\n\n2\nFebrero\n41500\n35400\n6300\n-200\nnegativo\n\n\n3\nMarzo\n51200\n35600\n7100\n8500\npositivo\n\n\n4\nAbril\n49700\n36300\n6850\n6550\npositivo\n\n\n\n\n\n\n\n\n\nFiltrar el conjunto de datos para quedarse con los nombres de los meses y los beneficios de los meses con balance positivo.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf[df.Balance .== \"positivo\", [:Mes, :Beneficios]]\n\n3√ó2 DataFrame\n\n\n\nRow\nMes\nBeneficios\n\n\n\nString\nInt64\n\n\n\n\n1\nEnero\n5150\n\n\n2\nMarzo\n8500\n\n\n3\nAbril\n6550\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 2.2 El fichero colesterol.csv contiene informaci√≥n de una muestra de pacientes donde se han medido la edad, el sexo, el peso, la altura y el nivel de colesterol, adem√°s de su nombre.\n\nCrear un data frame con los datos de todos los pacientes del estudio a partir del fichero colesterol.csv.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n CSV.read del paquete CSV para partir el rango de valores en intervalos y asociar a cada intervalo una categor√≠a.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CSV\ndf = CSV.read(\"datos/colesterol.csv\", DataFrame)\n\n14√ó6 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64?\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n\n\n2\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n\n\n3\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\n\n\n4\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n\n\n5\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n\n\n6\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n\n\n7\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n\n\n8\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\nmissing\n\n\n9\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n\n\n10\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n\n\n11\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n\n\n12\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n\n\n13\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n\n\n14\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n\n\n\n\n\n\n\n\n\nCrear una nueva columna con el √≠ndice de masa corporal, usando la siguiente f√≥rmula\n\\[\n\\mbox{IMC} = \\frac{\\mbox{Peso (kg)}}{\\mbox{Altura (cm)}^2}\n\\]\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf.imc = df.peso ./ (df.altura .^ 2)\ndf\n\n14√ó7 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64?\nFloat64?\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\n\n\n2\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\n\n\n3\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\nmissing\n\n\n4\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\n\n\n5\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\n\n\n6\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\n\n\n7\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\n\n\n8\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\nmissing\n21.7738\n\n\n9\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\n\n\n10\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\n\n\n11\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\n\n\n12\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\n\n\n13\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\n\n\n14\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\n\n\n\n\n\n\n\n\n\nCrear una nueva columna con la variable obesidad recodificando la columna imc en las siguientes categor√≠as.\n\n\n\nRango IMC\nCategor√≠a\n\n\n\n\nMenor de 18.5\nBajo peso\n\n\nDe 18.5 a 24.5\nSaludable\n\n\nDe 24.5 a 30\nSobrepeso\n\n\nMayor de 30\nObeso\n\n\n\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n cut del paquete CategoricalArrays para partir el rango de valores en intervalos y asociar a cada intervalo una categor√≠a.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CategoricalArrays\ndf.obesidad = cut(df.imc, [0, 18.5, 24.5, 30, Inf],\n                labels=[\"Bajo peso\", \"Saludable\", \"Sobrepeso\", \"Obeso\"],\n                extend=true)\ndf\n\n14√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64?\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n2\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n3\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n4\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n5\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n6\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n7\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n8\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\nmissing\n21.7738\nSaludable\n\n\n9\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n10\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n11\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n12\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n13\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n14\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nSeleccionar las columnas nombre, sexo y edad.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf[:, [:nombre, :sexo, :edad]]\n\n14√ó3 DataFrame\n\n\n\nRow\nnombre\nsexo\nedad\n\n\n\nString\nString1\nInt64\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\nH\n18\n\n\n2\nRosa D√≠az D√≠az\nM\n32\n\n\n3\nJavier Garc√≠a S√°nchez\nH\n24\n\n\n4\nCarmen L√≥pez Pinz√≥n\nM\n35\n\n\n5\nMarisa L√≥pez Collado\nM\n46\n\n\n6\nAntonio Ruiz Cruz\nH\n68\n\n\n7\nAntonio Fern√°ndez Oca√±a\nH\n51\n\n\n8\nPilar Mart√≠n Gonz√°lez\nM\n22\n\n\n9\nPedro G√°lvez Tenorio\nH\n35\n\n\n10\nSantiago Reillo Manzano\nH\n46\n\n\n11\nMacarena √Ålvarez Luna\nM\n53\n\n\n12\nJos√© Mar√≠a de la Gu√≠a Sanz\nH\n58\n\n\n13\nMiguel Angel Cuadrado Guti√©rrez\nH\n27\n\n\n14\nCarolina Rubio Moreno\nM\n20\n\n\n\n\n\n\n\n\n\nAnonimizar los datos eliminando la columna nombre.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n select del paquete DataFrames para seleccionar las columnas deseadas y eliminar las columnas no deseadas. Existe tambi√©n la funci√≥n select! que modifica el data frame original eliminando las columnas no seleccionadas.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nselect(df, Not(:nombre))\n\n14√ó7 DataFrame\n\n\n\nRow\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nInt64\nString1\nFloat64?\nFloat64\nFloat64?\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n2\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n3\n24\nH\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n4\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n5\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n6\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n7\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n8\n22\nM\n60.0\n1.66\nmissing\n21.7738\nSaludable\n\n\n9\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n10\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n11\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n12\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n13\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n14\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nReordenar las columnas poniendo la columna sexo antes que la columna edad.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nselect(df, Cols(:sexo, :edad, Not(:sexo, :edad)))\n\n14√ó8 DataFrame\n\n\n\nRow\nsexo\nedad\nnombre\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString1\nInt64\nString\nFloat64?\nFloat64\nFloat64?\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nH\n18\nJos√© Luis Mart√≠nez Izquierdo\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n2\nM\n32\nRosa D√≠az D√≠az\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n3\nH\n24\nJavier Garc√≠a S√°nchez\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n4\nM\n35\nCarmen L√≥pez Pinz√≥n\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n5\nM\n46\nMarisa L√≥pez Collado\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n6\nH\n68\nAntonio Ruiz Cruz\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n7\nH\n51\nAntonio Fern√°ndez Oca√±a\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n8\nM\n22\nPilar Mart√≠n Gonz√°lez\n60.0\n1.66\nmissing\n21.7738\nSaludable\n\n\n9\nH\n35\nPedro G√°lvez Tenorio\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n10\nH\n46\nSantiago Reillo Manzano\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n11\nM\n53\nMacarena √Ålvarez Luna\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n12\nH\n58\nJos√© Mar√≠a de la Gu√≠a Sanz\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n13\nH\n27\nMiguel Angel Cuadrado Guti√©rrez\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n14\nM\n20\nCarolina Rubio Moreno\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nFiltrar el data frame para quedarse con las mujeres.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf[df.sexo .== \"M\", :]\n\n6√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64?\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n2\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n3\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n4\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\nmissing\n21.7738\nSaludable\n\n\n5\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n6\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nFiltrar el data frame para quedarse con los hombres mayores de 30 a√±os.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndf[(df.sexo .== \"H\") .& (df.edad .&gt; 30), :]\n\n5√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64?\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n2\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n3\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n4\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n5\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n\n\n\n\n\n\n\nFiltrar el data frame para quedarse con las filas sin valores perdidos.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n dropmissing del paquete DataFrames para eliminar las filas con valores perdidos.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndropmissing(df)\n\n12√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64\nFloat64\nFloat64\nFloat64\nCat‚Ä¶\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n2\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n3\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n4\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n5\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n6\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n7\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n8\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n9\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n10\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n11\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n12\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nFiltrar el data frame para eliminar las filas con datos perdidos en la columna colesterol.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n dropmissing, col donde col es el nombre de la columna que contiene los valores perdidos.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndropmissing(df, :colesterol)    \n\n13√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n2\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n3\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n4\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n5\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n6\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n7\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n8\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n9\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n10\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n11\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n12\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n13\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nImputar los valores perdidos en la columna colesterol con la media de los valores no perdidos.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n coalesce para reemplazar los valores perdidos por otros valores.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing Statistics\nmedia_colesterol = mean(skipmissing(df.colesterol))\ndf.colesterol = coalesce.(df.colesterol, media_colesterol)\ndf\n\n14√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n2\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n3\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n4\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n5\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n6\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n7\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n8\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\n220.231\n21.7738\nSaludable\n\n\n9\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n10\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n11\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n12\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n13\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n14\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\nOrdenar el data frame seg√∫n la columna nombre.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n sort para ordenar las filas del data frame seg√∫n los valores de una o varias columnas. Utilizar el par√°metro rev para especificar mediante un vector de booleanos si el orden es ascendente o descendente.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nsort(df, :nombre)\n\n14√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n2\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n3\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n4\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n5\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n6\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n7\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n8\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n9\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n10\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n11\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n12\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\n220.231\n21.7738\nSaludable\n\n\n13\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n14\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n\n\n\n\n\n\n\nOrdenar el data frame ascendentemente por la columna sexo y descendentemente por la columna edad.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nsort(df, [:sexo, :edad], rev=[false, true])\n\n14√ó8 DataFrame\n\n\n\nRow\nnombre\nedad\nsexo\npeso\naltura\ncolesterol\nimc\nobesidad\n\n\n\nString\nInt64\nString1\nFloat64?\nFloat64\nFloat64\nFloat64?\nCat‚Ä¶?\n\n\n\n\n1\nAntonio Ruiz Cruz\n68\nH\n66.0\n1.74\n249.0\n21.7994\nSaludable\n\n\n2\nJos√© Mar√≠a de la Gu√≠a Sanz\n58\nH\n78.0\n1.87\n198.0\n22.3055\nSaludable\n\n\n3\nAntonio Fern√°ndez Oca√±a\n51\nH\n62.0\n1.72\n276.0\n20.9573\nSaludable\n\n\n4\nSantiago Reillo Manzano\n46\nH\n75.0\n1.85\n280.0\n21.9138\nSaludable\n\n\n5\nPedro G√°lvez Tenorio\n35\nH\n90.0\n1.94\n241.0\n23.9133\nSaludable\n\n\n6\nMiguel Angel Cuadrado Guti√©rrez\n27\nH\n109.0\n1.98\n210.0\n27.8033\nSobrepeso\n\n\n7\nJavier Garc√≠a S√°nchez\n24\nH\nmissing\n1.81\n191.0\nmissing\nmissing\n\n\n8\nJos√© Luis Mart√≠nez Izquierdo\n18\nH\n85.0\n1.79\n182.0\n26.5285\nSobrepeso\n\n\n9\nMacarena √Ålvarez Luna\n53\nM\n55.0\n1.62\n262.0\n20.9572\nSaludable\n\n\n10\nMarisa L√≥pez Collado\n46\nM\n51.0\n1.58\n148.0\n20.4294\nSaludable\n\n\n11\nCarmen L√≥pez Pinz√≥n\n35\nM\n65.0\n1.7\n200.0\n22.4913\nSaludable\n\n\n12\nRosa D√≠az D√≠az\n32\nM\n65.0\n1.73\n232.0\n21.7181\nSaludable\n\n\n13\nPilar Mart√≠n Gonz√°lez\n22\nM\n60.0\n1.66\n220.231\n21.7738\nSaludable\n\n\n14\nCarolina Rubio Moreno\n20\nM\n61.0\n1.77\n194.0\n19.4708\nSaludable\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 2.3 El fichero notas-curso2.csv contiene informaci√≥n de las notas de los alumnos de un curso.\n\nCrear un data frame con los datos de los alumnos del curso a partir del fichero notas-curso2.csv.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CSV, DataFrames\ndf = CSV.read(\"datos/notas-curso2.csv\", DataFrame; missingstring=\"NA\")\n\n120√ó9 DataFrame95 rows omitted\n\n\n\nRow\nsexo\nturno\ngrupo\ntrabaja\nnotaA\nnotaB\nnotaC\nnotaD\nnotaE\n\n\n\nString7\nString7\nString1\nString1\nFloat64\nFloat64?\nFloat64?\nFloat64?\nFloat64?\n\n\n\n\n1\nMujer\nTarde\nC\nN\n5.2\n6.3\n3.4\n2.3\n2.0\n\n\n2\nHombre\nMa√±ana\nA\nN\n5.7\n5.7\n4.2\n3.5\n2.7\n\n\n3\nHombre\nMa√±ana\nB\nN\n8.3\n8.8\n8.8\n8.0\n5.5\n\n\n4\nHombre\nMa√±ana\nB\nN\n6.1\n6.8\n4.0\n3.5\n2.2\n\n\n5\nHombre\nMa√±ana\nA\nN\n6.2\n9.0\n5.0\n4.4\n3.7\n\n\n6\nHombre\nMa√±ana\nA\nS\n8.6\n8.9\n9.5\n8.4\n3.9\n\n\n7\nMujer\nMa√±ana\nA\nN\n6.7\n7.9\n5.6\n4.8\n4.2\n\n\n8\nMujer\nTarde\nC\nS\n4.1\n5.2\n1.7\n0.3\n1.0\n\n\n9\nHombre\nTarde\nC\nN\n5.0\n5.0\n3.3\n2.7\n6.0\n\n\n10\nHombre\nTarde\nC\nN\n5.3\n6.3\n4.8\n3.6\n2.3\n\n\n11\nMujer\nMa√±ana\nA\nN\n7.8\nmissing\n6.5\n6.7\n2.8\n\n\n12\nHombre\nMa√±ana\nA\nN\n6.5\n8.0\n5.0\n3.2\n3.3\n\n\n13\nHombre\nMa√±ana\nB\nN\n6.6\n7.6\n5.3\n4.0\n1.0\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n109\nMujer\nTarde\nC\nN\n5.4\n7.3\n3.5\n2.5\n4.6\n\n\n110\nHombre\nMa√±ana\nB\nN\n7.4\n7.4\n6.2\n5.8\n1.1\n\n\n111\nMujer\nTarde\nC\nS\n5.1\n8.1\n5.2\n5.1\n4.5\n\n\n112\nHombre\nMa√±ana\nA\nN\n6.9\n7.8\n3.9\n2.8\nmissing\n\n\n113\nHombre\nTarde\nC\nN\n3.6\n4.8\n2.1\n0.5\n5.6\n\n\n114\nHombre\nTarde\nC\nS\n5.9\n6.2\n5.0\n3.9\n1.9\n\n\n115\nHombre\nMa√±ana\nB\nN\n6.8\n7.2\n4.9\n3.8\n2.8\n\n\n116\nHombre\nMa√±ana\nA\nN\n6.5\n6.1\n5.8\n4.9\n1.2\n\n\n117\nMujer\nMa√±ana\nB\nN\n6.2\n7.0\n5.6\n5.4\n1.7\n\n\n118\nMujer\nTarde\nC\nN\n5.0\n6.5\n4.0\n2.8\n3.6\n\n\n119\nHombre\nTarde\nC\nN\n4.7\n6.0\n1.3\n0.4\n2.2\n\n\n120\nHombre\nTarde\nC\nS\n4.5\n4.7\n6.0\n4.9\n1.8\n\n\n\n\n\n\n\n\n\nObtener el n√∫mero de datos perdidos en cada columna.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndescribe(df)[:, [:variable, :nmissing]]\n\n9√ó2 DataFrame\n\n\n\nRow\nvariable\nnmissing\n\n\n\nSymbol\nInt64\n\n\n\n\n1\nsexo\n0\n\n\n2\nturno\n0\n\n\n3\ngrupo\n0\n\n\n4\ntrabaja\n0\n\n\n5\nnotaA\n0\n\n\n6\nnotaB\n5\n\n\n7\nnotaC\n1\n\n\n8\nnotaD\n2\n\n\n9\nnotaE\n2\n\n\n\n\n\n\n\n\n\nRecodificar la variable grupo en una colecci√≥n de columnas binarias.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n onehotbatch del paquete OneHotArrays para recodificar una variable categ√≥rica en una colecci√≥n de columnas binarias.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing OneHotArrays\ncodificacion = permutedims(onehotbatch(df.grupo, unique(df.grupo)))\nhcat(df, DataFrame(codificacion, :auto))\n\n120√ó12 DataFrame95 rows omitted\n\n\n\nRow\nsexo\nturno\ngrupo\ntrabaja\nnotaA\nnotaB\nnotaC\nnotaD\nnotaE\nx1\nx2\nx3\n\n\n\nString7\nString7\nString1\nString1\nFloat64\nFloat64?\nFloat64?\nFloat64?\nFloat64?\nBool\nBool\nBool\n\n\n\n\n1\nMujer\nTarde\nC\nN\n5.2\n6.3\n3.4\n2.3\n2.0\ntrue\nfalse\nfalse\n\n\n2\nHombre\nMa√±ana\nA\nN\n5.7\n5.7\n4.2\n3.5\n2.7\nfalse\ntrue\nfalse\n\n\n3\nHombre\nMa√±ana\nB\nN\n8.3\n8.8\n8.8\n8.0\n5.5\nfalse\nfalse\ntrue\n\n\n4\nHombre\nMa√±ana\nB\nN\n6.1\n6.8\n4.0\n3.5\n2.2\nfalse\nfalse\ntrue\n\n\n5\nHombre\nMa√±ana\nA\nN\n6.2\n9.0\n5.0\n4.4\n3.7\nfalse\ntrue\nfalse\n\n\n6\nHombre\nMa√±ana\nA\nS\n8.6\n8.9\n9.5\n8.4\n3.9\nfalse\ntrue\nfalse\n\n\n7\nMujer\nMa√±ana\nA\nN\n6.7\n7.9\n5.6\n4.8\n4.2\nfalse\ntrue\nfalse\n\n\n8\nMujer\nTarde\nC\nS\n4.1\n5.2\n1.7\n0.3\n1.0\ntrue\nfalse\nfalse\n\n\n9\nHombre\nTarde\nC\nN\n5.0\n5.0\n3.3\n2.7\n6.0\ntrue\nfalse\nfalse\n\n\n10\nHombre\nTarde\nC\nN\n5.3\n6.3\n4.8\n3.6\n2.3\ntrue\nfalse\nfalse\n\n\n11\nMujer\nMa√±ana\nA\nN\n7.8\nmissing\n6.5\n6.7\n2.8\nfalse\ntrue\nfalse\n\n\n12\nHombre\nMa√±ana\nA\nN\n6.5\n8.0\n5.0\n3.2\n3.3\nfalse\ntrue\nfalse\n\n\n13\nHombre\nMa√±ana\nB\nN\n6.6\n7.6\n5.3\n4.0\n1.0\nfalse\nfalse\ntrue\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n109\nMujer\nTarde\nC\nN\n5.4\n7.3\n3.5\n2.5\n4.6\ntrue\nfalse\nfalse\n\n\n110\nHombre\nMa√±ana\nB\nN\n7.4\n7.4\n6.2\n5.8\n1.1\nfalse\nfalse\ntrue\n\n\n111\nMujer\nTarde\nC\nS\n5.1\n8.1\n5.2\n5.1\n4.5\ntrue\nfalse\nfalse\n\n\n112\nHombre\nMa√±ana\nA\nN\n6.9\n7.8\n3.9\n2.8\nmissing\nfalse\ntrue\nfalse\n\n\n113\nHombre\nTarde\nC\nN\n3.6\n4.8\n2.1\n0.5\n5.6\ntrue\nfalse\nfalse\n\n\n114\nHombre\nTarde\nC\nS\n5.9\n6.2\n5.0\n3.9\n1.9\ntrue\nfalse\nfalse\n\n\n115\nHombre\nMa√±ana\nB\nN\n6.8\n7.2\n4.9\n3.8\n2.8\nfalse\nfalse\ntrue\n\n\n116\nHombre\nMa√±ana\nA\nN\n6.5\n6.1\n5.8\n4.9\n1.2\nfalse\ntrue\nfalse\n\n\n117\nMujer\nMa√±ana\nB\nN\n6.2\n7.0\n5.6\n5.4\n1.7\nfalse\nfalse\ntrue\n\n\n118\nMujer\nTarde\nC\nN\n5.0\n6.5\n4.0\n2.8\n3.6\ntrue\nfalse\nfalse\n\n\n119\nHombre\nTarde\nC\nN\n4.7\n6.0\n1.3\n0.4\n2.2\ntrue\nfalse\nfalse\n\n\n120\nHombre\nTarde\nC\nS\n4.5\n4.7\n6.0\n4.9\n1.8\ntrue\nfalse\nfalse",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preprocesamiento de datos</span>"
    ]
  },
  {
    "objectID": "02-preprocesamiento.html#ejercicios-propuestos",
    "href": "02-preprocesamiento.html#ejercicios-propuestos",
    "title": "2¬† Preprocesamiento de datos",
    "section": "2.2 Ejercicios propuestos",
    "text": "2.2 Ejercicios propuestos\n\nEjercicio 2.4 Calcular el d√©cimo t√©rmino de la sucesi√≥n \\(\\left(\\frac{3n^2+n}{6n^2-1}\\right)_{n=1}^\\infty\\).\n\n\n\n\n  \n    \n      \n\n    \n    \n\n    \n    ¬†üéÅ\n\n\n         \n    \n    \n    \n\n\n\n\n\n\n\n\nEjercicio 2.5 Los ficheros vinos-blancos.xls y vinos-tintos.csv contienen informaci√≥n sobre las caracter√≠sticas de vinos blancos y tintos portugueses de la denominaci√≥n ‚ÄúVinho Verde‚Äù. Las variables almacenadas en estos archivos son las siguientes:\n\n\n\n\n\n\n\n\nVariable\nDescripci√≥n\nTipo (unidades)\n\n\n\n\ntipo\nTipo de vino\nFactor (blanco, tinto)\n\n\nmeses.barrica\nMesesde envejecimiento en barrica\nNum√©rica(meses)\n\n\nacided.fija\nCantidadde √°cidotart√°rico\nNum√©rica(g/dm3)\n\n\nacided.volatil\nCantidad de √°cido ac√©tico\nNum√©rica(g/dm3)\n\n\nacido.citrico\nCantidad de √°cidoc√≠trico\nNum√©rica(g/dm3)\n\n\nazucar.residual\nCantidad de az√∫carremanente despu√©s de la fermentaci√≥n\nNum√©rica(g/dm3)\n\n\ncloruro.sodico\nCantidad de cloruros√≥dico\nNum√©rica(g/dm3)\n\n\ndioxido.azufre.libre\nCantidad de di√≥xido de azufreen formalibre\nNum√©rica(mg/dm3)\n\n\ndioxido.azufre.total\nCantidadde di√≥xido de azufretotal en forma libre o ligada\nNum√©rica(mg/dm3)\n\n\ndensidad\nDensidad\nNum√©rica(g/cm3)\n\n\nph\npH\nNum√©rica(0-14)\n\n\nsulfatos\nCantidadde sulfato de potasio\nNum√©rica(g/dm3)\n\n\nalcohol\nPorcentajede contenidode alcohol\nNum√©rica(0-100)\n\n\ncalidad\nCalificaci√≥n otorgada porun panel de expertos\nNum√©rica(0-10)\n\n\n\n\nCrear un data frame con los datos de los vinos blancos partir del fichero de Excel vinos-blancos.xlsx.\nCrear un data frame con los datos de los vinos tintos partir del fichero csv vinos-tintos.csv.\nFusionar los datos de los vinos blancos y tintos en un nuevo data frame.\nConvertir el tipo de vino en un factor.\nImputar los valores perdidos del alcohol con la media de los valores no perdidos para cada tipo de vino.\nCrear un factor Envejecimiento recodificando la variable meses.barrica en las siguientes categor√≠as.\n\n\n\nRango en meses\nCategor√≠a\n\n\n\n\nMenos de 3\nJoven\n\n\nEntre 3 y 12\nCrianza\n\n\nEntre 12 y 18\nReserva\n\n\nM√°s de 18\nGran reserva\n\n\n\nCrear un factor Dulzor recodificando la variable azucar.residual en las siguientes categor√≠as.\n\n\n\nRango az√∫car\nCategor√≠a\n\n\n\n\nMenos de 4\nSeco\n\n\nM√°s de 4 y menos de 12\nSemiseco\n\n\nM√°s de 12 y menos de 45\nSemidulce\n\n\nM√°s de 45\nDulce\n\n\n\nFiltrar el conjunto de datos para quedarse con los vinos Reserva o Gran Reserva con una calidad superior a 7 y ordenar el data frame por calidad de forma descendente.\n¬øCu√°ntos vinos blancos con un contenido en alcohol superior al 12% y una calidad superior a 8 hay en el conjunto de datos?",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Preprocesamiento de datos</span>"
    ]
  },
  {
    "objectID": "03-regresion.html",
    "href": "03-regresion.html",
    "title": "3¬† Regresi√≥n",
    "section": "",
    "text": "3.1 Ejercicios Resueltos\nLos modelos de aprendizaje basados en regresi√≥n son modelos bastante simples que pueden utilizarse para predecir variables cuantitativas (regresi√≥n lineal) o cualitativas (regresi√≥n log√≠stica). Esta pr√°ctica contiene ejercicios que muestran como construir modelos de aprendizaje de regresi√≥n lineal y regresi√≥n log√≠stica con Julia.\nPara la realizaci√≥n de esta pr√°ctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n</span>"
    ]
  },
  {
    "objectID": "03-regresion.html#ejercicios-resueltos",
    "href": "03-regresion.html#ejercicios-resueltos",
    "title": "3¬† Regresi√≥n",
    "section": "",
    "text": "using CSV  # Para la lectura de archivos CSV.\nusing DataFrames  # Para el manejo de datos tabulares.\nusing PrettyTables  # Para mostrar tablas formateadas.\nusing Plots  # Para el dibujo de gr√°ficas.\nusing GLMakie  # Para obtener gr√°ficos interactivos.\n\nEjercicio 3.1 El conjunto de datos viviendas.csv contiene informaci√≥n sobre el precio de venta de viviendas en una ciudad.\n\nCargar los datos del archivo viviendas.csv en un data frame.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CSV, DataFrames\ndf = CSV.read(\"datos/viviendas.csv\", DataFrame)\nfirst(df, 5)\n\n5√ó13 DataFrame\n\n\n\nRow\nprecio\narea\ndormitorios\nba√±os\nhabitaciones\ncalleprincipal\nhuespedes\nsotano\ncalentador\nclimatizacion\ngaraje\ncentrico\namueblado\n\n\n\nInt64\nInt64\nInt64\nInt64\nInt64\nString3\nString3\nString3\nString3\nString3\nInt64\nString3\nString15\n\n\n\n\n1\n13300000\n7420\n4\n2\n3\nsi\nno\nno\nno\nsi\n2\nsi\namueblado\n\n\n2\n12250000\n8960\n4\n4\n4\nsi\nno\nno\nno\nsi\n3\nno\namueblado\n\n\n3\n12250000\n9960\n3\n2\n2\nsi\nno\nsi\nno\nno\n2\nsi\nsemi-amueblado\n\n\n4\n12215000\n7500\n4\n2\n2\nsi\nno\nsi\nno\nsi\n3\nsi\namueblado\n\n\n5\n11410000\n7420\n4\n1\n2\nsi\nsi\nsi\nno\nsi\n2\nno\namueblado\n\n\n\n\n\n\n\n\n\nDibujar un diagrama de dispersi√≥n entre el precio y el area de las viviendas.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing Plots\nplt = scatter(df.area, df.precio, xlabel=\"Area\", ylabel=\"Precio\", title=\"Precio vs Area\", label = \"Ejemplos\", fmt=:png,)\n\n\n\n\n\n\n\nDefinir un modelo lineal que explique el precio en funci√≥n del √°rea de las viviendas.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUn modelo lineal tiene encuaci√≥n \\(y = \\theta_1 + \\theta_2 x\\).\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nprecio(area, Œ∏) = Œ∏[1] .+ Œ∏[2] * area\n\nprecio (generic function with 1 method)\n\n\nObserva que la funci√≥n precio est√° vectorizada, lo que significa que puede recibir un vector de √°reas y devolver un vector de precios.\n\n\n\nInicializar los par√°metros del modelo lineal con valores nulos y dibujar el modelo sobre el diagrama de dispersi√≥n.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nŒ∏ = [0.0, 0.0]\nplot!(df.area, precio(df.area, Œ∏), label = \"Modelo 0\")\n\n\n\n\n\n\n\nDefinir una funci√≥n de costo para el modelo lineal y evaluar el coste para el modelo lineal construido con los par√°metros iniciales. A la vista del coste obtenido, ¬øc√≥mo de bueno es el modelo?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nLa funci√≥n de coste para un modelo lineal es el error cuadr√°tico medio.\n\\[ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 \\]\ndonde \\(h_\\theta\\) es el modelo, \\(h_\\theta(x^{(i)})\\) es la predicci√≥n del modelo para el ejemplo \\(i\\)-√©simo, \\(y^{(i)}\\) es el valor real observado para el ejemplo \\(i\\)-√©simo, y \\(m\\) es el n√∫mero de ejemplos.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nfunction coste(Œ∏, X, Y)\n    m = length(Y)\n    return sum((precio(X, Œ∏) .- Y).^2) / (2 * m)\nend\n\ncoste(Œ∏, df.area, df.precio)\n\n1.3106916364659266e13\n\n\nLa funci√≥n de coste nos da una medida de lo lejos que est√°n las predicciones del modelo de los valores reales observados. En este caso, el coste es muy alto, lo que indica que el modelo no es bueno.\n\n\n\n¬øEn qu√© direcci√≥n debemos modificar los par√°metros del modelo para mejorar el modelo?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\nPara minimizar la funci√≥n de coste, debemos modificar los par√°metros del modelo en la direcci√≥n opuesta al gradiente de la funci√≥n de coste, ya que el gradiente de una funci√≥n indica la direcci√≥n de mayor crecimiento de la funci√≥n.\n\n\n\nCrear una funci√≥n para modificar los pesos del modelo lineal mediante el algoritmo del gradiente descendente, y aplicarla a los par√°metros actuales tomando una tasa de aprendizaje de \\(10^{-8}\\). ¬øC√≥mo han cambiado los par√°metros del modelo? Dibujar el modelo actualizado sobre el diagrama de dispersi√≥n. ¬øC√≥mo ha cambiado el coste?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nEl algoritmo del gradiente descendente actualiza los par√°metros del modelo de acuerdo a la siguiente regla:\n\\[\n\\theta_j = \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n\\]\ndonde \\(\\alpha\\) es la tasa de aprendizaje y \\(\\frac{\\partial J(\\theta)}{\\partial \\theta_j}\\) es la derivada parcial de la funci√≥n de coste con respecto al par√°metro \\(\\theta_j\\).\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nfunction gradiente_descendente!(Œ∏, X, Y, Œ±)\n    # Calculamos el n√∫mero de ejemplos\n    m = length(Y)\n    # Actualizamos el t√©rmino independiente del modelo lineal.\n    Œ∏[1] -= Œ± * sum(precio(X, Œ∏) - Y) / m\n    # Actualizamos la pendiente del modelo lineal.\n    Œ∏[2] -= Œ± * sum((precio(X, Œ∏) - Y) .* X) / m\n    return Œ∏\nend\n\ngradiente_descendente! (generic function with 1 method)\n\n\nAplicamos la funci√≥n a los par√°metros del modelo actual y mostramos los nuevos par√°metros.\n\ngradiente_descendente!(Œ∏, df.area, df.precio, 1e-8)\nŒ∏\n\n2-element Vector{Float64}:\n   0.04766729247706422\n 267.22919804579385\n\n\nDibujamos el nuevo modelo.\n\nplot!(df.area, precio(df.area, Œ∏), label = \"Modelo 1\")\n\n\n\n\nSe observa que ahora la recta est√° m√°s cerca de la nube de puntos, por lo que el modelo ha mejorado. Calculamos el coste del nuevo modelo.\n\ncoste(Œ∏, df.area, df.precio)\n\n7.080823787113201e12\n\n\n\n\n\nRepetir el proceso de actualizaci√≥n de los par√°metros del modelo mediante el algoritmo del gradiente descendente durante 9 iteraciones m√°s y dibujar los modelos actualizados.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\nfor i = 2:10\n    gradiente_descendente!(Œ∏, df.area, df.precio, 1e-8)\n    plot!(df.area, precio(df.area, Œ∏), label = \"Modelo $i\", legend = true)\nend\nplt\n\n\n\n\nDibujar un gr√°fico con la evoluci√≥n del coste del modelo a lo largo de las iteraciones. ¬øC√≥mo se comporta el coste a lo largo de las iteraciones?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ncostes = Float64[]\nfor i = 1:10\n    gradiente_descendente!(Œ∏, df.area, df.precio, 1e-8)\n    push!(costes, coste(Œ∏, df.area, df.precio))\nend\ncostes\n\n10-element Vector{Float64}:\n 4.230808760870044e12\n 2.882906194020343e12\n 2.2454213686913755e12\n 1.9439256128790886e12\n 1.8013344680594421e12\n 1.7338965877160208e12\n 1.7020021263374993e12\n 1.6869177748236997e12\n 1.6797836937723748e12\n 1.6764096595632322e12\n\n\nEl coste del modelo disminuye en cada iteraci√≥n, lo que indica que el modelo est√° mejorando. Esto se debe a que el algoritmo del gradiente descendente modifica los par√°metros del modelo en la direcci√≥n que minimiza la funci√≥n de coste.\n\n\n\n¬øHasta qu√© iteraci√≥n habr√° que llegar para conseguir un reducci√≥n del coste menor de un \\(0.0001\\%\\)?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nŒ∏ = [0.0, 0.0]\ncostes = [0, coste(Œ∏, df.area, df.precio)]\ni = 1\nwhile abs(costes[end] - costes[end-1]) / costes[end-1] &gt; 0.000001\n    i += 1\n    gradiente_descendente!(Œ∏, df.area, df.precio, 1e-8)\n    push!(costes, coste(Œ∏, df.area, df.precio))\nend\ni\n\n23\n\n\nEn este caso, el algoritmo del gradiente descendente converge en 1000 iteraciones.\n\n\n\n¬øQu√© sucede si se utiliza una tasa de aprendizaje \\(\\alpha = 0.0001\\)? ¬øC√≥mo afecta al coste y a la convergencia del modelo?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nŒ∏ = [0.0, 0.0]\ncostes = [coste(Œ∏, df.area, df.precio)]\nfor i = 1:10\n    gradiente_descendente!(Œ∏, df.area, df.precio, 0.0001)\n    push!(costes, coste(Œ∏, df.area, df.precio))\nend\ncostes\n\n11-element Vector{Float64}:\n 1.3106916364659266e13\n 1.114133369099188e20\n 1.0856750832581238e27\n 1.05794371802143e34\n 1.0309206941949286e41\n 1.004587918634273e48\n 9.789277603492545e54\n 9.539230386975057e61\n 9.29557011881276e68\n 9.058133657380397e75\n 8.826762028174244e82\n\n\nSi la tasa de aprendizaje es demasiado grande, el algoritmo del gradiente descendente puede no converger y el coste puede oscilar en lugar de disminuir. En este caso, el coste aumenta en cada iteraci√≥n, lo que indica que la tasa de aprendizaje es demasiado grande.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Regresi√≥n</span>"
    ]
  },
  {
    "objectID": "07-arboles-decision.html",
    "href": "07-arboles-decision.html",
    "title": "4¬† √Årboles de decisi√≥n",
    "section": "",
    "text": "4.1 Ejercicios Resueltos\nLos √°rboles de decisi√≥n son modelos de aprendizaje simples e intuitivos que pueden utilizarse para tanto para predecir variables cuantitativas (regresi√≥n) como categ√≥ricas (clasificaci√≥n). Esta pr√°ctica contiene ejercicios que muestran como construir modelos de aprendizaje basados en √°rboles de decisi√≥n con Julia.\nPara la realizaci√≥n de esta pr√°ctica se requieren los siguientes paquetes:",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>√Årboles de decisi√≥n</span>"
    ]
  },
  {
    "objectID": "07-arboles-decision.html#ejercicios-resueltos",
    "href": "07-arboles-decision.html#ejercicios-resueltos",
    "title": "4¬† √Årboles de decisi√≥n",
    "section": "",
    "text": "using CSV  # Para la lectura de archivos CSV.\nusing DataFrames  # Para el manejo de datos tabulares.\nusing Tidier # Para el preprocesamiento de datos.\nusing PrettyTables  # Para mostrar tablas formateadas.\nusing Plots  # Para el dibujo de gr√°ficas.\nusing GLMakie  # Para obtener gr√°ficos interactivos.\nusing AlgebraOfGraphics # Para generar gr√°ficos mediante la gram√°tica de gr√°ficos.\nusing DecisionTree # Para construir √°rboles de decisi√≥n.\nusing GraphMakie # Para la visualizaci√≥n de √°rboles de decisi√≥n.\n\nEjercicio 4.1 El conjunto de datos tenis.csv contiene informaci√≥n sobre las condiciones meteorol√≥gicas de varios d√≠as y si se pudo jugar al tenis o no.\n\nCargar los datos del archivo tenis.csv en un data frame.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CSV, DataFrames\ndf = CSV.read(\"datos/tenis.csv\", DataFrame)\n\n14√ó5 DataFrame\n\n\n\nRow\nCielo\nTemperatura\nHumedad\nViento\nTenis\n\n\n\nString15\nString15\nString7\nString7\nString3\n\n\n\n\n1\nSoleado\nCaluroso\nAlta\nSuave\nNo\n\n\n2\nSoleado\nCaluroso\nAlta\nFuerte\nNo\n\n\n3\nNublado\nCaluroso\nAlta\nSuave\nS√≠\n\n\n4\nLluvioso\nModerado\nAlta\nSuave\nS√≠\n\n\n5\nLluvioso\nFr√≠o\nNormal\nSuave\nS√≠\n\n\n6\nLluvioso\nFr√≠o\nNormal\nFuerte\nNo\n\n\n7\nNublado\nFr√≠o\nNormal\nFuerte\nS√≠\n\n\n8\nSoleado\nModerado\nAlta\nSuave\nNo\n\n\n9\nSoleado\nFr√≠o\nNormal\nSuave\nS√≠\n\n\n10\nLluvioso\nModerado\nNormal\nSuave\nS√≠\n\n\n11\nSoleado\nModerado\nNormal\nFuerte\nS√≠\n\n\n12\nNublado\nModerado\nAlta\nFuerte\nS√≠\n\n\n13\nNublado\nCaluroso\nNormal\nSuave\nS√≠\n\n\n14\nLluvioso\nModerado\nAlta\nFuerte\nNo\n\n\n\n\n\n\n\n\n\nCrear un diagrama de barras que muestre la distribuci√≥n de frecuencias de cada variable meteorol√≥gica seg√∫n si se pudo jugar al tenis o no. ¬øQu√© variable meteorol√≥gica parece tener m√°s influencia en la decisi√≥n de jugar al tenis?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing GLMakie, AlgebraOfGraphics\n\nfunction frecuencias(df::DataFrame, var::Symbol)\n    # Calculamos el n√∫mero de d√≠as de cada clase que se juega al tenis.\n    frec = combine(groupby(df, [var, :Tenis]), nrow =&gt; :D√≠as)\n    # Dibujamos el diagrama de barras.\n    plt = data(frec) * \n    mapping(var, :D√≠as, stack = :Tenis, color = :Tenis, ) * \n    visual(BarPlot) \n    # Devolvemos el gr√°fico.\n    return plt\nend\n\nfig = Figure()\ndraw!(fig[1, 1], frecuencias(df, :Cielo))\ndraw!(fig[1, 2], frecuencias(df, :Temperatura))\ndraw!(fig[1, 3], frecuencias(df, :Humedad))\ndraw!(fig[1, 4], frecuencias(df, :Viento))\nfig\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\nA la vista de las frecuencias de cada variable, las variable Cielo y Humedad parecen ser las que m√°s influye en la decisi√≥n de jugar al tenis.\n\n\n\nCalcular la impureza del conjunto de datos utilizando el √≠ndice de Gini. ¬øQu√© variable meteorol√≥gica parece tener m√°s influencia en la decisi√≥n de jugar al tenis?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nEl √≠ndice de Gini se calcula mediante la f√≥rmula\n\\[ GI = 1 - \\sum_{i=1}^{n} p_i^2 \\]\ndonde \\(p_i\\) es la proporci√≥n de cada clase en el conjunto de datos y \\(n\\) es el n√∫mero de clases.\nEl √≠ndice de Gini toma valores entre \\(0\\) y \\(1-\\frac{1}{n}\\) (\\(0.5\\) en el caso de clasificaci√≥n binaria), donde \\(0\\) indica que todas las instancias pertenecen a una sola clase (m√≠nima impureza) y \\(1-\\frac{1}{n}\\) indica que las instancias est√°n distribuidas uniformemente entre todas las clases (m√°xima impureza).\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nfunction gini(df::DataFrame, var::Symbol)\n    # Calculamos el n√∫mero de ejemplos.\n    n = nrow(df)\n    # Calculamos las frecuencias absolutas de cada clase.\n    frec = combine(groupby(df, var), nrow =&gt; :ni)\n    # Calculamos la proporci√≥n de cada clase.\n    frec.p = frec.ni ./ n\n    # Calculamos el √≠ndice de Gini.\n    gini = 1 - sum(frec.p .^ 2)\n    return gini\nend\n\ng0 = gini(df, :Tenis)\n\n0.4591836734693877\n\n\n\n\n\n¬øQu√© reducci√≥n del √≠ndice Gini se obtiene si dividimos el conjunto de ejemplos seg√∫n la variable Humedad? ¬øY si dividimos el conjunto con respecto a la variable Viento?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nLa reducci√≥n del √≠ndice de Gini se calcula como la diferencia entre el √≠ndice de Gini del conjunto original y el √≠ndice de Gini del conjunto dividido.\n\\[ \\Delta GI = GI_{original} - GI_{dividido} \\]\ndonde el √≠ndice de Gini del conjunto dividido es la media ponderada de los √≠ndices de Gini de los subconjuntos resultantes de la divisi√≥n.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\nCalculamos primero la reducci√≥n del √≠ndice de Gini al dividir el conjunto de ejemplos seg√∫n la variable Humedad.\n\nusing Tidier\n# Dividimos el conjunto de ejemplos seg√∫n la variable Humedad.\ndf_humedad_alta = @filter(df, Humedad == \"Alta\")\ndf_humedad_normal = @filter(df, Humedad == \"Normal\")\n# Calculamos los tama√±os de los subconjuntos de ejemplos.\nn = nrow(df_humedad_alta), nrow(df_humedad_normal)\n# Calculamos el √≠ndice de Gini de cada subconjunto.\ngis = gini(df_humedad_alta, :Tenis), gini(df_humedad_normal, :Tenis)\n# Calculamos media ponderada de los √≠ndices de Gini de los subconjuntos \ng_humedad = sum(gis .* n) / sum(n)\n# Calculamos la reducci√≥n del √≠ndice de Gini.\ng0 - g_humedad\n\n0.09183673469387743\n\n\nCalculamos ahora la reducci√≥n del √≠ndice de Gini al dividir el conjunto de ejemplos seg√∫n la variable Viento.\n\n# Dividimos el conjunto de ejemplos seg√∫n la variable `Viento`\ndf_viento_fuerte = @filter(df, Viento == \"Fuerte\")\ndf_viento_suave = @filter(df, Viento == \"Suave\")\n# Calculamos los tama√±os de los subconjuntos de ejemplos\nn = nrow(df_viento_fuerte), nrow(df_viento_suave)\n# Calculamos el √≠ndice de Gini de cada subconjunto\ngis = gini(df_viento_fuerte, :Tenis), gini(df_viento_suave, :Tenis)\n# Calculamos media ponderada de los √≠ndices de Gini de los subconjuntos\ng_viento = sum(gis .* n) / sum(n)\n# Calculamos la reducci√≥n del √≠ndice de Gini\ng0 - g_viento\n\n0.030612244897959162\n\n\nComo se puede observar, la reducci√≥n del √≠ndice de Gini al dividir el conjunto de ejemplos seg√∫n la variable Humedad es mayor que la reducci√≥n del √≠ndice de Gini al dividir el conjunto con respecto a la variable Viento. Por lo tanto, la variable Humedad parece tener m√°s influencia en la decisi√≥n de jugar al tenis y ser√≠a la variable que se deber√≠a elegir para dividir el conjunto de ejemplos.\n\n\n\nConstruir un √°rbol de decisi√≥n que explique si se puede jugar al tenis en funci√≥n de las variables meteorol√≥gicas.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n DecisionTreeClassifier del paquete DecisionTree.jl.\nLos par√°metros m√°s importantes de esta funci√≥n son:\n\nmax_depth: Profundidad m√°xima del √°rbol. Si no se indica, el √°rbol crecer√° hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos de min_samples_split ejemplos.\nmin_samples_leaf: N√∫mero m√≠nimo de ejemplos en una hoja (1 por defecto).\nmin_samples_split: N√∫mero m√≠nimo de ejemplos para dividir un nodo (2 por defecto).\nmin_impurity_decrease: Reducci√≥n m√≠nima de la impureza para dividir un nodo (0 por defecto).\npost-prune: Si se indica true, se poda el √°rbol despu√©s de que se ha construido. La poda reduce el tama√±o del √°rbol eliminando nodos que no aportan informaci√≥n √∫til.\nmerge_purity_threshold: Umbral de pureza para fusionar nodos. Si se indica, se fusionan los nodos que tienen una pureza menor que este umbral.\nfeature_importance: Indica la medida para calcular la importancia de las variables a la hora de dividir el conjunto de datos. Puede ser :impurity o :split. Si no se indica, se utiliza la impureza de Gini.\nrng: Indica la semilla para la generaci√≥n de n√∫meros aleatorios. Si no se indica, se utiliza el generador de n√∫meros aleatorios por defecto.\n\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing DecisionTree, CategoricalArrays\n# Variables predictoras.\nX = Matrix(select(df, Not(:Tenis)))\n# Variable objetivo.\ny = df.Tenis\n# Convertir las variables categ√≥ricas a enteros.\nX = hcat([levelcode.(categorical(X[:, j])) for j in 1:size(X, 2)]...)\n# Convertir la variable objetivo a enteros.\ny = levelcode.(categorical(y))\ntree = DecisionTreeClassifier(max_depth=3)\nfit!(tree, X, y)\n\nDecisionTreeClassifier\nmax_depth:                3\nmin_samples_leaf:         1\nmin_samples_split:        2\nmin_purity_increase:      0.0\npruning_purity_threshold: 1.0\nn_subfeatures:            0\nclasses:                  [1, 2]\nroot:                     Decision Tree\nLeaves: 6\nDepth:  3\n\n\n\n\n\nVisualizar el √°rbol de decisi√≥n construido.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n plot_tree del paquete DecisionTree.jl.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nprint_tree(tree, feature_names=names(df)[1:end-1])\n\nFeature 3: \"Humedad\" &lt; 2.0 ?\n‚îú‚îÄ Feature 1: \"Cielo\" &lt; 3.0 ?\n    ‚îú‚îÄ Feature 4: \"Viento\" &lt; 2.0 ?\n        ‚îú‚îÄ 2 : 1/2\n        ‚îî‚îÄ 2 : 2/2\n    ‚îî‚îÄ 1 : 3/3\n‚îî‚îÄ Feature 4: \"Viento\" &lt; 2.0 ?\n    ‚îú‚îÄ Feature 1: \"Cielo\" &lt; 2.0 ?\n        ‚îú‚îÄ 1 : 1/1\n        ‚îî‚îÄ 2 : 2/2\n    ‚îî‚îÄ 2 : 4/4\n\n\n\n\n\n\n\n\nEjercicio 4.2 El conjunto de datos ping√ºinos.csv contiene un conjunto de datos sobre tres eEspecie de ping√ºinos con las siguientes variables:\n\nEspecie: Especie de ping√ºino, com√∫nmente Adelie, Chinstrap o Gentoo.\nIsla: Isla del archipi√©lago Palmer donde se realiz√≥ la observaci√≥n.\nLongitud_pico: Longitud del pico en mm.\nProfundidad_pico: Profundidad del pico en mm\nLongitud_ala: Longitud de la aleta en mm.\nPeso: Masa corporal en gramos.\nSexo: Sexo\n\n\nCargar los datos del archivo pingu√Ønos.csv en un data frame.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CSV, DataFrames\ndf = CSV.read(\"datos/ping√ºinos.csv\", DataFrame, missingstring=\"NA\")\n\n344√ó7 DataFrame319 rows omitted\n\n\n\nRow\nEspecie\nIsla\nLongitud_pico\nProfundidad_pico\nLongitud_ala\nPeso\nSexo\n\n\n\nString15\nString15\nFloat64?\nFloat64?\nInt64?\nInt64?\nString7?\n\n\n\n\n1\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmacho\n\n\n2\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nhembra\n\n\n3\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nhembra\n\n\n4\nAdelie\nTorgersen\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n5\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nhembra\n\n\n6\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmacho\n\n\n7\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nhembra\n\n\n8\nAdelie\nTorgersen\n39.2\n19.6\n195\n4675\nmacho\n\n\n9\nAdelie\nTorgersen\n34.1\n18.1\n193\n3475\nmissing\n\n\n10\nAdelie\nTorgersen\n42.0\n20.2\n190\n4250\nmissing\n\n\n11\nAdelie\nTorgersen\n37.8\n17.1\n186\n3300\nmissing\n\n\n12\nAdelie\nTorgersen\n37.8\n17.3\n180\n3700\nmissing\n\n\n13\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nhembra\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n333\nChinstrap\nDream\n45.2\n16.6\n191\n3250\nhembra\n\n\n334\nChinstrap\nDream\n49.3\n19.9\n203\n4050\nmacho\n\n\n335\nChinstrap\nDream\n50.2\n18.8\n202\n3800\nmacho\n\n\n336\nChinstrap\nDream\n45.6\n19.4\n194\n3525\nhembra\n\n\n337\nChinstrap\nDream\n51.9\n19.5\n206\n3950\nmacho\n\n\n338\nChinstrap\nDream\n46.8\n16.5\n189\n3650\nhembra\n\n\n339\nChinstrap\nDream\n45.7\n17.0\n195\n3650\nhembra\n\n\n340\nChinstrap\nDream\n55.8\n19.8\n207\n4000\nmacho\n\n\n341\nChinstrap\nDream\n43.5\n18.1\n202\n3400\nhembra\n\n\n342\nChinstrap\nDream\n49.6\n18.2\n193\n3775\nmacho\n\n\n343\nChinstrap\nDream\n50.8\n19.0\n210\n4100\nmacho\n\n\n344\nChinstrap\nDream\n50.2\n18.7\n198\n3775\nhembra\n\n\n\n\n\n\n\n\n\nHacer un an√°lisis de los datos perdidos en el data frame.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndescribe(df, :nmissing)\n\n7√ó2 DataFrame\n\n\n\nRow\nvariable\nnmissing\n\n\n\nSymbol\nInt64\n\n\n\n\n1\nEspecie\n0\n\n\n2\nIsla\n0\n\n\n3\nLongitud_pico\n2\n\n\n4\nProfundidad_pico\n2\n\n\n5\nLongitud_ala\n2\n\n\n6\nPeso\n2\n\n\n7\nSexo\n11\n\n\n\n\n\n\n\n\n\nEliminar del data frame los casos con valores perdidos.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndropmissing!(df)\n\n333√ó7 DataFrame308 rows omitted\n\n\n\nRow\nEspecie\nIsla\nLongitud_pico\nProfundidad_pico\nLongitud_ala\nPeso\nSexo\n\n\n\nString15\nString15\nFloat64\nFloat64\nInt64\nInt64\nString7\n\n\n\n\n1\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmacho\n\n\n2\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nhembra\n\n\n3\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nhembra\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nhembra\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmacho\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nhembra\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195\n4675\nmacho\n\n\n8\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nhembra\n\n\n9\nAdelie\nTorgersen\n38.6\n21.2\n191\n3800\nmacho\n\n\n10\nAdelie\nTorgersen\n34.6\n21.1\n198\n4400\nmacho\n\n\n11\nAdelie\nTorgersen\n36.6\n17.8\n185\n3700\nhembra\n\n\n12\nAdelie\nTorgersen\n38.7\n19.0\n195\n3450\nhembra\n\n\n13\nAdelie\nTorgersen\n42.5\n20.7\n197\n4500\nmacho\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n322\nChinstrap\nDream\n45.2\n16.6\n191\n3250\nhembra\n\n\n323\nChinstrap\nDream\n49.3\n19.9\n203\n4050\nmacho\n\n\n324\nChinstrap\nDream\n50.2\n18.8\n202\n3800\nmacho\n\n\n325\nChinstrap\nDream\n45.6\n19.4\n194\n3525\nhembra\n\n\n326\nChinstrap\nDream\n51.9\n19.5\n206\n3950\nmacho\n\n\n327\nChinstrap\nDream\n46.8\n16.5\n189\n3650\nhembra\n\n\n328\nChinstrap\nDream\n45.7\n17.0\n195\n3650\nhembra\n\n\n329\nChinstrap\nDream\n55.8\n19.8\n207\n4000\nmacho\n\n\n330\nChinstrap\nDream\n43.5\n18.1\n202\n3400\nhembra\n\n\n331\nChinstrap\nDream\n49.6\n18.2\n193\n3775\nmacho\n\n\n332\nChinstrap\nDream\n50.8\n19.0\n210\n4100\nmacho\n\n\n333\nChinstrap\nDream\n50.2\n18.7\n198\n3775\nhembra\n\n\n\n\n\n\n\n\n\nCrear diagramas que muestren la distribuci√≥n de frecuencias de cada variable seg√∫n la especie de ping√ºino. ¬øQu√© variable parece tener m√°s influencia en la especie de ping√ºino?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\nPara las variables cualitativas dibujamos diagramas de barras.\n\nusing GLMakie, AlgebraOfGraphics\n\nfrec_isla = combine(groupby(df, [:Isla, :Especie]), nrow =&gt; :Frecuencia)\ndata(frec_isla) * \n    mapping(:Isla, :Frecuencia, stack = :Especie, color =:Especie) *\n    visual(BarPlot) |&gt; draw\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\nfrec_sexo = combine(groupby(df, [:Sexo, :Especie]), nrow =&gt; :Frecuencia)\ndata(frec_sexo) * \n    mapping(:Sexo, :Frecuencia, stack = :Especie, color =:Especie) *\n    visual(BarPlot) |&gt; draw\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\nPara las variables cuantitativas dibujamos diagramas de cajas.\n\nfunction cajas(df, var, clase)\n    data(df) *\n        mapping(clase, var, color = clase) *\n        visual(BoxPlot) |&gt; \n        draw\nend\n\ncajas(df, :Longitud_pico, :Especie)\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\ncajas(df, :Profundidad_pico, :Especie)\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\ncajas(df, :Longitud_ala, :Especie)\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\ncajas(df, :Peso, :Especie)\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\n\n\n¬øCu√°l es la reducci√≥n de la impureza del conjunto de datos si dividimos el conjunto de datos en dos conjuntos seg√∫n si la longitud del pico es mayor o menor que 44 mm?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing Tidier\nfunction gini(df::DataFrame, var::Symbol)\n    n = nrow(df)\n    frec = combine(groupby(df, var), nrow =&gt; :ni)\n    frec.p = frec.ni ./ n\n    gini = 1 - sum(frec.p .^ 2)\n    return gini\nend\n\nfunction reduccion_impureza(df::DataFrame, var::Symbol, val::Number)\n    # Dividimos el conjunto de ejemplos seg√∫n la longitud del pico es menor de 44.\n    df_menor = @eval @filter($df, $var &lt;= $val)\n    df_mayor = @eval @filter($df, $var &gt; $val)\n    # Calculamos los tama√±os de los subconjuntos de ejemplos.\n    n = nrow(df_menor), nrow(df_mayor)\n    # Calculamos el √≠ndice de Gini de cada subconjunto.\n    gis = gini(df_menor, :Especie), gini(df_mayor, :Especie)\n    # Calculamos media ponderada de los √≠ndices de Gini de los subconjuntos.\n    g1 = sum(gis .* n) / sum(n)\n    # Calculamos la reducci√≥n del √≠ndice de Gini.\n    gini(df, :Especie) - g1\nend\n\nreduccion_impureza(df, :Longitud_pico, 44)\n\n0.26577182779353914\n\n\n\n\n\nDeterminar el valor √≥ptimo de divisi√≥n del conjunto de datos seg√∫n la longitud del pico. Para ello, calcular la reducci√≥n de la impureza para cada valor de longitud del pico y dibujar el resultado.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\nDibujamos la reducci√≥n de la impureza en funci√≥n de la longitud del pico.\n\nusing Plots\n# Valores √∫nicos de longitud del pico.\nvalores = unique(df.Longitud_pico)\n# Reducci√≥n de la impureza para cada valor.\nreducciones = [reduccion_impureza(df, :Longitud_pico, val) for val in valores]\n# Graficamos el resultado.\nPlots.scatter(valores, reducciones, xlabel = \"Longitud del pico\", ylabel = \"Reducci√≥n de la impureza\", legend = false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY ahora obtenemos el valor √≥ptimo de divisi√≥n del conjunto de datos seg√∫n la longitud del pico.\n\nval_optimo = valores[argmax(reducciones)]\n\n42.3\n\n\n\n\n\nDividir aleatoriamente el dataframe en un conjunto de entrenamiento y un conjunto de test con proporciones \\(3/4\\) y \\(1/4\\) respectivamente.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n shuffle del paquete Random para barajar el dataframe y luego dividirlo en dos subconjuntos.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing Random\n# Establecemos la semilla para la reproducibilidad.\nRandom.seed!(1234)\n# Barajamos el dataframe.\ndf = shuffle(df)\n# Dividimos el dataframe en un conjunto de entrenamiento y un conjunto de test.\nn = nrow(df)\ndf_test = df[1:div(n, 4), :]\ndf_train = df[div(n, 4)+1:end, :]\n\n250√ó7 DataFrame225 rows omitted\n\n\n\nRow\nEspecie\nIsla\nLongitud_pico\nProfundidad_pico\nLongitud_ala\nPeso\nSexo\n\n\n\nString15\nString15\nFloat64\nFloat64\nInt64\nInt64\nString7\n\n\n\n\n1\nAdelie\nDream\n39.0\n18.7\n185\n3650\nmacho\n\n\n2\nChinstrap\nDream\n52.8\n20.0\n205\n4550\nmacho\n\n\n3\nChinstrap\nDream\n55.8\n19.8\n207\n4000\nmacho\n\n\n4\nAdelie\nTorgersen\n35.1\n19.4\n193\n4200\nmacho\n\n\n5\nAdelie\nTorgersen\n34.6\n21.1\n198\n4400\nmacho\n\n\n6\nGentoo\nBiscoe\n50.0\n15.2\n218\n5700\nmacho\n\n\n7\nChinstrap\nDream\n50.6\n19.4\n193\n3800\nmacho\n\n\n8\nChinstrap\nDream\n43.5\n18.1\n202\n3400\nhembra\n\n\n9\nAdelie\nDream\n36.9\n18.6\n189\n3500\nhembra\n\n\n10\nAdelie\nDream\n36.6\n18.4\n184\n3475\nhembra\n\n\n11\nChinstrap\nDream\n46.6\n17.8\n193\n3800\nhembra\n\n\n12\nGentoo\nBiscoe\n50.8\n17.3\n228\n5600\nmacho\n\n\n13\nChinstrap\nDream\n52.2\n18.8\n197\n3450\nmacho\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n239\nAdelie\nDream\n39.8\n19.1\n184\n4650\nmacho\n\n\n240\nAdelie\nTorgersen\n43.1\n19.2\n197\n3500\nmacho\n\n\n241\nChinstrap\nDream\n49.8\n17.3\n198\n3675\nhembra\n\n\n242\nGentoo\nBiscoe\n49.8\n15.9\n229\n5950\nmacho\n\n\n243\nChinstrap\nDream\n50.8\n18.5\n201\n4450\nmacho\n\n\n244\nGentoo\nBiscoe\n50.7\n15.0\n223\n5550\nmacho\n\n\n245\nGentoo\nBiscoe\n46.2\n14.1\n217\n4375\nhembra\n\n\n246\nAdelie\nTorgersen\n35.5\n17.5\n190\n3700\nhembra\n\n\n247\nAdelie\nBiscoe\n39.7\n18.9\n184\n3550\nmacho\n\n\n248\nGentoo\nBiscoe\n47.7\n15.0\n216\n4750\nhembra\n\n\n249\nAdelie\nTorgersen\n42.9\n17.6\n196\n4700\nmacho\n\n\n250\nAdelie\nDream\n40.8\n18.9\n208\n4300\nmacho\n\n\n\n\n\n\n\n\n\nConstruir un √°rbol de decisi√≥n con el conjunto de entrenamiento sin tener en cuenta la variable Isla y visualizarlo.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing DecisionTree, CategoricalArrays\n# Variables predictivas.\nX_train = Matrix(select(df_train, Not(:Isla, :Especie)))\n# Variable objetivo.\ny_train = df_train.Especie\n# Convertir las variables categ√≥ricas a enteros.\nX_train = hcat([levelcode.(categorical(X_train[:, j])) for j in 1:size(X_train, 2)]...)\n# Convertir la variable objetivo a enteros\ny_train = levelcode.(categorical(y_train))\n\n# Construimos el √°rbol de decisi√≥n con profundidad m√°xima 3.\ntree = DecisionTreeClassifier(max_depth = 3)\nfit!(tree, X_train, y_train)\nprint_tree(tree, feature_names=names(df)[3:end])\n\nFeature 3: \"Longitud_ala\" &lt; 29.0 ?\n‚îú‚îÄ Feature 1: \"Longitud_pico\" &lt; 62.0 ?\n    ‚îú‚îÄ 1 : 96/96\n    ‚îî‚îÄ Feature 1: \"Longitud_pico\" &lt; 87.0 ?\n        ‚îú‚îÄ 2 : 10/20\n        ‚îî‚îÄ 2 : 37/38\n‚îî‚îÄ Feature 2: \"Profundidad_pico\" &lt; 46.0 ?\n    ‚îú‚îÄ 3 : 90/90\n    ‚îî‚îÄ Feature 1: \"Longitud_pico\" &lt; 109.0 ?\n        ‚îú‚îÄ 1 : 2/2\n        ‚îî‚îÄ 2 : 4/4\n\n\n\n\n\nPredecir la especie de los ping√ºinos del conjunto de test y calcular la matriz de confusi√≥n de las predicciones.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUtilizar la funci√≥n confmat del paquete StatisticalMeaures para barajar el dataframe y luego dividirlo en dos subconjuntos.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing StatisticalMeasures\n# Variables predictivas\nX_test = Matrix(select(df_test, Not(:Isla, :Especie)))\n# Variable objetivo\ny_test = df_test.Especie\n# Convertir las variables categ√≥ricas a enteros\nX_test = hcat([levelcode.(categorical(X_test[:, j])) for j in 1:size(X_test, 2)]...)\n# Convertir la variable objetivo a enteros\ny_test = levelcode.(categorical(y_test))\n# Predecimos la especie de ping√ºino del conjunto de test\ny_pred = predict(tree, X_test)\n# Calculamos la precisi√≥n del modelo\nconfmat(y_pred, y_test)\n\n          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n          ‚îÇ Ground Truth ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇPredicted‚îÇ 1  ‚îÇ 2  ‚îÇ 3  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ    1    ‚îÇ 38 ‚îÇ 11 ‚îÇ 9  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ    2    ‚îÇ 0  ‚îÇ 6  ‚îÇ 0  ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ    3    ‚îÇ 0  ‚îÇ 0  ‚îÇ 19 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\nCalcular la precisi√≥n del modelo.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nLa precisi√≥n es la proporci√≥n de predicciones correctas sobre el total de predicciones.\nUtilizar la funci√≥n accuracy del paquete StatisticalMeaures para calcular la precisi√≥n del modelo.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Calculamos la precisi√≥n del modelo\naccuracy(y_pred, y_test)\n\n0.7590361445783133\n\n\n\n\n\n\n\n\nEjercicio 4.3 El fichero vinos.csv contiene informaci√≥n sobre las caracter√≠sticas de una muestra de vinos portugueses de la denominaci√≥n ‚ÄúVinho Verde‚Äù. Las variables que contiene son:\n\n\n\n\n\n\n\n\nVariable\nDescripci√≥n\nTipo (unidades)\n\n\n\n\ntipo\nTipo de vino\nCateg√≥rica (blanco, tinto)\n\n\nmeses.barrica\nMesesde envejecimiento en barrica\nNum√©rica(meses)\n\n\nacided.fija\nCantidadde √°cidotart√°rico\nNum√©rica(g/dm3)\n\n\nacided.volatil\nCantidad de √°cido ac√©tico\nNum√©rica(g/dm3)\n\n\nacido.citrico\nCantidad de √°cidoc√≠trico\nNum√©rica(g/dm3)\n\n\nazucar.residual\nCantidad de az√∫carremanente despu√©s de la fermentaci√≥n\nNum√©rica(g/dm3)\n\n\ncloruro.sodico\nCantidad de cloruros√≥dico\nNum√©rica(g/dm3)\n\n\ndioxido.azufre.libre\nCantidad de di√≥xido de azufreen formalibre\nNum√©rica(mg/dm3)\n\n\ndioxido.azufre.total\nCantidadde di√≥xido de azufretotal en forma libre o ligada\nNum√©rica(mg/dm3)\n\n\ndensidad\nDensidad\nNum√©rica(g/cm3)\n\n\nph\npH\nNum√©rica(0-14)\n\n\nsulfatos\nCantidadde sulfato de potasio\nNum√©rica(g/dm3)\n\n\nalcohol\nPorcentajede contenidode alcohol\nNum√©rica(0-100)\n\n\ncalidad\nCalificaci√≥n otorgada porun panel de expertos\nNum√©rica(0-10)\n\n\n\n\nCrear un data frame con los datos de los vinos a partir del fichero vinos.csv.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CSV, DataFrames\ndf = CSV.read(\"datos/vinos.csv\", DataFrame)\n\n5320√ó14 DataFrame5295 rows omitted\n\n\n\nRow\ntipo\nmeses_barrica\nacided_fija\nacided_volatil\nacido_citrico\nazucar_residual\ncloruro_sodico\ndioxido_azufre_libre\ndioxido_azufre_total\ndensidad\nph\nsulfatos\nalcohol\ncalidad\n\n\n\nString7\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nInt64\n\n\n\n\n1\nblanco\n0\n7.0\n0.27\n0.36\n20.7\n0.045\n45.0\n170.0\n1.001\n3.0\n0.45\n8.8\n6\n\n\n2\nblanco\n0\n6.3\n0.3\n0.34\n1.6\n0.049\n14.0\n132.0\n0.994\n3.3\n0.49\n9.5\n6\n\n\n3\nblanco\n0\n8.1\n0.28\n0.4\n6.9\n0.05\n30.0\n97.0\n0.9951\n3.26\n0.44\n10.1\n6\n\n\n4\nblanco\n0\n7.2\n0.23\n0.32\n8.5\n0.058\n47.0\n186.0\n0.9956\n3.19\n0.4\n9.9\n6\n\n\n5\nblanco\n0\n6.2\n0.32\n0.16\n7.0\n0.045\n30.0\n136.0\n0.9949\n3.18\n0.47\n9.6\n6\n\n\n6\nblanco\n0\n8.1\n0.22\n0.43\n1.5\n0.044\n28.0\n129.0\n0.9938\n3.22\n0.45\n11.0\n6\n\n\n7\nblanco\n0\n8.1\n0.27\n0.41\n1.45\n0.033\n11.0\n63.0\n0.9908\n2.99\n0.56\n12.0\n5\n\n\n8\nblanco\n0\n8.6\n0.23\n0.4\n4.2\n0.035\n17.0\n109.0\n0.9947\n3.14\n0.53\n9.7\n5\n\n\n9\nblanco\n0\n7.9\n0.18\n0.37\n1.2\n0.04\n16.0\n75.0\n0.992\n3.18\n0.63\n10.8\n5\n\n\n10\nblanco\n0\n6.6\n0.16\n0.4\n1.5\n0.044\n48.0\n143.0\n0.9912\n3.54\n0.52\n12.4\n7\n\n\n11\nblanco\n0\n8.3\n0.42\n0.62\n19.25\n0.04\n41.0\n172.0\n1.0002\n2.98\n0.67\n9.7\n5\n\n\n12\nblanco\n0\n6.6\n0.17\n0.38\n1.5\n0.032\n28.0\n112.0\n0.9914\n3.25\n0.55\n11.4\n7\n\n\n13\nblanco\n0\n6.3\n0.48\n0.04\n1.1\n0.046\n30.0\n99.0\n0.9928\n3.24\n0.36\n9.6\n6\n\n\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n‚ãÆ\n\n\n5309\ntinto\n7\n7.5\n0.31\n0.41\n2.4\n0.065\n34.0\n60.0\n0.99492\n3.34\n0.85\n11.4\n6\n\n\n5310\ntinto\n7\n5.8\n0.61\n0.11\n1.8\n0.066\n18.0\n28.0\n0.99483\n3.55\n0.66\n10.9\n6\n\n\n5311\ntinto\n10\n7.2\n0.66\n0.33\n2.5\n0.068\n34.0\n102.0\n0.99414\n3.27\n0.78\n12.8\n6\n\n\n5312\ntinto\n3\n6.6\n0.725\n0.2\n7.8\n0.073\n29.0\n79.0\n0.9977\n3.29\n0.54\n9.2\n5\n\n\n5313\ntinto\n7\n6.3\n0.55\n0.15\n1.8\n0.077\n26.0\n35.0\n0.99314\n3.32\n0.82\n11.6\n6\n\n\n5314\ntinto\n9\n5.4\n0.74\n0.09\n1.7\n0.089\n16.0\n26.0\n0.99402\n3.67\n0.56\n11.6\n6\n\n\n5315\ntinto\n3\n6.3\n0.51\n0.13\n2.3\n0.076\n29.0\n40.0\n0.99574\n3.42\n0.75\n11.0\n6\n\n\n5316\ntinto\n3\n6.8\n0.62\n0.08\n1.9\n0.068\n28.0\n38.0\n0.99651\n3.42\n0.82\n9.5\n6\n\n\n5317\ntinto\n5\n6.2\n0.6\n0.08\n2.0\n0.09\n32.0\n44.0\n0.9949\n3.45\n0.58\n10.5\n5\n\n\n5318\ntinto\n10\n5.9\n0.55\n0.1\n2.2\n0.062\n39.0\n51.0\n0.99512\n3.52\n0.76\n11.2\n6\n\n\n5319\ntinto\n6\n5.9\n0.645\n0.12\n2.0\n0.075\n32.0\n44.0\n0.99547\n3.57\n0.71\n10.2\n5\n\n\n5320\ntinto\n3\n6.0\n0.31\n0.47\n3.6\n0.067\n18.0\n42.0\n0.99549\n3.39\n0.66\n11.0\n6\n\n\n\n\n\n\n\n\n\nMostrar los tipos de cada variable del data frame.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n schema del paquete MLJ.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing MLJ\nschema(df)\n\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ names                ‚îÇ scitypes   ‚îÇ types   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ tipo                 ‚îÇ Textual    ‚îÇ String7 ‚îÇ\n‚îÇ meses_barrica        ‚îÇ Count      ‚îÇ Int64   ‚îÇ\n‚îÇ acided_fija          ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ acided_volatil       ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ acido_citrico        ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ azucar_residual      ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ cloruro_sodico       ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ dioxido_azufre_libre ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ dioxido_azufre_total ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ densidad             ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ ph                   ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ sulfatos             ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ alcohol              ‚îÇ Continuous ‚îÇ Float64 ‚îÇ\n‚îÇ calidad              ‚îÇ Count      ‚îÇ Int64   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n\nHacer un an√°lisis de los datos perdidos en el data frame.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ndescribe(df, :nmissing)\n\n14√ó2 DataFrame\n\n\n\nRow\nvariable\nnmissing\n\n\n\nSymbol\nInt64\n\n\n\n\n1\ntipo\n0\n\n\n2\nmeses_barrica\n0\n\n\n3\nacided_fija\n0\n\n\n4\nacided_volatil\n0\n\n\n5\nacido_citrico\n0\n\n\n6\nazucar_residual\n0\n\n\n7\ncloruro_sodico\n0\n\n\n8\ndioxido_azufre_libre\n0\n\n\n9\ndioxido_azufre_total\n0\n\n\n10\ndensidad\n0\n\n\n11\nph\n0\n\n\n12\nsulfatos\n0\n\n\n13\nalcohol\n0\n\n\n14\ncalidad\n0\n\n\n\n\n\n\n\n\n\nMostrar la distribuci√≥n de frecuencias de las variables cuantitativas del data frame mediante histogramas.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing GLMakie\nfig = Figure() \nax = [Axis(fig[trunc(Int, i / 3), i % 3], title = names(df)[i+2]) for i in 0:12]\nfor i in 1:13\n    hist!(ax[i], df[!, i+1], strokewidth = 0.5, strokecolor = (:white, 0.5))\nend\nfig\n\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\n\n\nSe considera que un vino es bueno si tiene una puntuaci√≥n de calidad mayor que \\(6.5\\). Recodificar la variable calidad en una variable categ√≥rica que tome el valor 1 si la calidad es mayor que \\(6.5\\) y 0 en caso contrario.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nusing CategoricalArrays\n# Recodificamos la variable calidad.\ndf.calidad = cut(df.calidad, [0, 6.5, 10], labels = [\" ‚òπÔ∏è \", \" üòä \"])\n\n5320-element CategoricalArray{String,1,UInt32}:\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" üòä \"\n \" ‚òπÔ∏è \"\n \" üòä \"\n \" ‚òπÔ∏è \"\n ‚ãÆ\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n\n\n\n\n\nDescomponer el data frame en un data frame con las variables predictivas y un vector con la variable objetivo bueno.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\ny, X = unpack(df, ==(:calidad), rng = 123)\n\n\n(CategoricalValue{String, UInt32}[\" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" üòä \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \"  ‚Ä¶  \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \", \" ‚òπÔ∏è \"], 5320√ó13 DataFrame\n  Row ‚îÇ tipo     meses_barrica  acided_fija  acided_volatil  acido_citrico  az ‚ãØ\n      ‚îÇ String7  Int64          Float64      Float64         Float64        Fl ‚ãØ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    1 ‚îÇ blanco               0          6.7           0.5             0.36     ‚ãØ\n    2 ‚îÇ blanco               0          6.3           0.2             0.3\n    3 ‚îÇ blanco               0          6.2           0.35            0.03\n    4 ‚îÇ tinto                3          8.0           0.39            0.3\n    5 ‚îÇ blanco               0          7.9           0.255           0.26     ‚ãØ\n    6 ‚îÇ blanco               0          6.1           0.31            0.37\n    7 ‚îÇ blanco               0          6.8           0.28            0.36\n    8 ‚îÇ blanco               0          8.2           0.34            0.49\n    9 ‚îÇ tinto                0          6.7           0.48            0.02     ‚ãØ\n   10 ‚îÇ blanco               0          7.4           0.35            0.2\n   11 ‚îÇ tinto                5          7.5           0.53            0.06\n  ‚ãÆ   ‚îÇ    ‚ãÆ           ‚ãÆ             ‚ãÆ             ‚ãÆ               ‚ãÆ           ‚ã±\n 5311 ‚îÇ blanco               0          7.2           0.14            0.35\n 5312 ‚îÇ tinto                3          7.6           0.41            0.24     ‚ãØ\n 5313 ‚îÇ tinto                0          7.3           0.4             0.3\n 5314 ‚îÇ tinto                4          7.1           0.48            0.28\n 5315 ‚îÇ blanco               0          6.4           0.29            0.2\n 5316 ‚îÇ blanco               0          9.4           0.24            0.29     ‚ãØ\n 5317 ‚îÇ blanco               0          6.3           0.25            0.27\n 5318 ‚îÇ blanco               0          5.5           0.16            0.26\n 5319 ‚îÇ blanco               0          7.4           0.36            0.32\n 5320 ‚îÇ blanco               0          7.6           0.51            0.24     ‚ãØ\n                                                 8 columns and 5299 rows omitted)\n\n\n\n\n\n\nPara poder entrenar un modelo de un arbol de decisi√≥n, las variables predictivas deben ser cuantitativas. Transmformar las variables categ√≥ricas en variables num√©ricas.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Convertir las variables categ√≥ricas a enteros.\ncoerce!(X, :tipo =&gt; OrderedFactor, :meses_barrica =&gt; Continuous)\nschema(X)\n\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ names                ‚îÇ scitypes         ‚îÇ types                             ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ tipo                 ‚îÇ OrderedFactor{2} ‚îÇ CategoricalValue{String7, UInt32} ‚îÇ\n‚îÇ meses_barrica        ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ acided_fija          ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ acided_volatil       ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ acido_citrico        ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ azucar_residual      ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ cloruro_sodico       ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ dioxido_azufre_libre ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ dioxido_azufre_total ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ densidad             ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ ph                   ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ sulfatos             ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îÇ alcohol              ‚îÇ Continuous       ‚îÇ Float64                           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n\nDefinir un modelo de √°rbol de decisi√≥n con profundidad m√°xima 3.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nCargar el modelo DecisionTreeClassifier del paquete DecisionTree con la macros @iload.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Cargamos el tipo de modelo.\nTree = @iload DecisionTreeClassifier pkg = \"DecisionTree\"\n# Instanciamos el modelo con sus par√°metros.\narbol = Tree(max_depth =3, rng = 123)\n\nimport MLJDecisionTreeInterface ‚úî\n\n\n[ Info: For silent loading, specify `verbosity=0`. \n\n\nDecisionTreeClassifier(\n  max_depth = 3, \n  min_samples_leaf = 1, \n  min_samples_split = 2, \n  min_purity_increase = 0.0, \n  n_subfeatures = 0, \n  post_prune = false, \n  merge_purity_threshold = 1.0, \n  display_depth = 5, \n  feature_importance = :impurity, \n  rng = 123)\n\n\n\n\n\nEvaluar el modelo tomando un 70% de ejemplos en el conjunto de entrenamiento y un 30% en el conjunto de test. Utilizar como m√©trica la precisi√≥n.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n evaluate del paquete MLJ para evaluar el modelo. Los par√°metros m√°s importantes de esta funci√≥n son:\n\nresampling: Indica el m√©todo de muestreo para definir los conjuntos de entrenamiento y test. Los m√©todos m√°s habituales son:\n\nHoldout(fraction_train = p): Divide el conjunto de datos tomando una proporci√≥n de \\(p\\) ejemplos en el conjunto de entrenamiento y \\(1-p\\) en el conjunto de test.\nCV(nfolds = n, shuffle = true|false): Utiliza validaci√≥n cruzada con n iteraciones. Si se indica shuffle = true, se utiliza validaci√≥n cruzada aleatoria.\nStratifiedCV(nfolds = n, shuffle = true|false): Utiliza validaci√≥n cruzada estratificada con n iteraciones. Si se indica shuffle = true, se utiliza validaci√≥n cruzada estratificada aleatoria.\nInSample(): Utiliza el conjunto de entrenamiento como conjunto de test.\n\nmeasures: Indica las m√©tricas a utilizar para evaluar el modelo. Las m√©tricas m√°s habituales son:\n\ncross_entropy: P√©rdida de entrop√≠a cruzada.\nconfusion_matrix: Matriz de confusi√≥n.\ntrue_positive_rate: Tasa de verdaderos positivos.\ntrue_negative_rate: Tasa de verdaderos negativos.\nppv: Valor predictivo positivo.\nnpv: Valor predictivo negativo.\naccuracy: Precisi√≥n.\n\nSe puede indicar m√°s de una en un vector.\n\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nevaluate(arbol, X, y, resampling = Holdout(fraction_train = 0.7, rng = 123), measures = accuracy)\n\n\nPerformanceEvaluation object with these fields:\n  model, measure, operation,\n  measurement, per_fold, per_observation,\n  fitted_params_per_fold, report_per_fold,\n  train_test_rows, resampling, repeats\nExtract:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ measure    ‚îÇ operation    ‚îÇ measurement ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Accuracy() ‚îÇ predict_mode ‚îÇ 0.843       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n\nEvaluar el modelo mediante validaci√≥n cruzada estratificada usando las m√©tricas de la p√©rdida de entrop√≠a cruzada, la matriz de confusi√≥n, la tasa de verdaderos positivos, la tasa de verdaderos negativos, el valor predictivo positivo, el valor predictivo negativo y la precisi√≥n. ¬øEs un buen modelo?\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nevaluate(arbol, X, y, resampling = StratifiedCV(rng = 123), measures = [cross_entropy, confusion_matrix, true_positive_rate, true_negative_rate, ppv, npv, accuracy])\n\nEvaluating over 6 folds:  83%[====================&gt;    ]  ETA: 0:00:00Evaluating over 6 folds: 100%[=========================] Time: 0:00:00\n\n\n\nPerformanceEvaluation object with these fields:\n  model, measure, operation,\n  measurement, per_fold, per_observation,\n  fitted_params_per_fold, report_per_fold,\n  train_test_rows, resampling, repeats\nExtract:\n‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ   ‚îÇ measure                  ‚îÇ operation    ‚îÇ measurement                    ‚ãØ\n‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ A ‚îÇ LogLoss(                 ‚îÇ predict      ‚îÇ 0.375                          ‚ãØ\n‚îÇ   ‚îÇ   tol = 2.22045e-16)     ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ B ‚îÇ ConfusionMatrix(         ‚îÇ predict_mode ‚îÇ ConfusionMatrix{2}([3821534 78 ‚ãØ\n‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   perm = nothing,        ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ C ‚îÇ TruePositiveRate(        ‚îÇ predict_mode ‚îÇ 0.128                          ‚ãØ\n‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ D ‚îÇ TrueNegativeRate(        ‚îÇ predict_mode ‚îÇ 1.0                            ‚ãØ\n‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ E ‚îÇ PositivePredictiveValue( ‚îÇ predict_mode ‚îÇ 0.994                          ‚ãØ\n‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   checks = true)         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ F ‚îÇ NegativePredictiveValue( ‚îÇ predict_mode ‚îÇ 0.83                           ‚ãØ\n‚îÇ   ‚îÇ   levels = nothing,      ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ   ‚îÇ   rev = nothing,         ‚îÇ              ‚îÇ                                ‚ãØ\n‚îÇ ‚ãÆ ‚îÇ            ‚ãÆ             ‚îÇ      ‚ãÆ       ‚îÇ                        ‚ãÆ       ‚ã±\n‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                                     1 column and 2 rows omitted\n‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ   ‚îÇ per_fold                                                                 ‚ãØ\n‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ A ‚îÇ [0.391, 0.394, 0.35, 0.358, 0.365, 0.391]                                ‚ãØ\n‚îÇ B ‚îÇ ConfusionMatrix{2, true, CategoricalValue{String, UInt32}}[ConfusionMatr ‚ãØ\n‚îÇ C ‚îÇ [0.125, 0.167, 0.155, 0.112, 0.113, 0.0952]                              ‚ãØ\n‚îÇ D ‚îÇ [1.0, 0.999, 1.0, 1.0, 1.0, 1.0]                                         ‚ãØ\n‚îÇ E ‚îÇ [1.0, 0.966, 1.0, 1.0, 1.0, 1.0]                                         ‚ãØ\n‚îÇ F ‚îÇ [0.83, 0.837, 0.835, 0.827, 0.828, 0.825]                                ‚ãØ\n‚îÇ G ‚îÇ [0.834, 0.841, 0.84, 0.831, 0.832, 0.828]                                ‚ãØ\n‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                                               2 columns omitted\n\n\n\n\nLa precisi√≥n del modelo es de \\(0.834\\) que no est√° mal, pero si consdieramos la tasa de verdadero positivos, que es \\(0.13\\) y la tasa de verdaderos negativos, que es pr√°cticamente 1, el modelo tiene un buen rendimiento en la clasificaci√≥n de los vinos malos, pero un mal rendimiento en la clasificaci√≥n de los vinos buenos. Por lo tanto, no podemos decir que sea un buen modelo.\n\n\n\nConstruir √°rboles de decisi√≥n con profundidades m√°ximas de 2 a 10 y evaluar el modelo con validaci√≥n cruzada estratificada. ¬øCu√°l es la profundidad m√°xima que da mejor resultado?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n TunedModel del paquete MLJ para ajustar los par√°metros del modelo.\nLos par√°metros m√°s importantes de esta funci√≥n son:\n\nmodel: Indica el modelo a ajustar.\nresampling: Indica el m√©todo de muestreo para definir los conjuntos de entrenamiento y test.\ntuning: Indica el m√©todo de ajuste de los par√°metros del modelo. Los m√©todos m√°s habituales son:\n\nGrid(resolution = n): Ajusta los par√°metros del modelo utilizando una cuadr√≠cula de b√∫squeda con n valores.\nRandomSearch(resolution = n): Ajusta los par√°metros del modelo utilizando una b√∫squeda aleatoria con n valores.\n\nrange: Indica el rango de valores a utilizar para ajustar los par√°metros del modelo. Se puede indicar un rango de valores o un vector de valores.\nmeasure: Indica la m√©trica a utilizar para evaluar el modelo.\n\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Instanciamos el modelo de √°rbol de decisi√≥n.\narbol = Tree()\n# Definimos el rango de valores a utilizar para ajustar los par√°metros del modelo.\nr = range(arbol, :max_depth, lower=2, upper=10)\n# Ajustamos los par√°metros del modelo utilizando una cuadr√≠cula de b√∫squeda con 9 valores.\narbol_parametrizado = TunedModel(\n    model = arbol,\n    resampling = StratifiedCV(rng = 123),\n    tuning = Grid(resolution = 9),\n    range = r,\n    measure = accuracy)\n# Definimos una m√°quina de aprendizaje con el modelo, las variables predictivas y la variable objetivo.\nmach = machine(arbol_parametrizado, X, y)\n# Ajustamos los par√°metros del modelo.\nMLJ.fit!(mach)\n# Mostramos los par√°metros del mejor modelo.\nfitted_params(mach).best_model\n\n[ Info: Training machine(ProbabilisticTunedModel(model = DecisionTreeClassifier(max_depth = -1, ‚Ä¶), ‚Ä¶), ‚Ä¶).\n[ Info: Attempting to evaluate 9 models.\nEvaluating over 9 metamodels:  22%[=====&gt;                   ]  ETA: 0:00:01Evaluating over 9 metamodels:  33%[========&gt;                ]  ETA: 0:00:01Evaluating over 9 metamodels:  44%[===========&gt;             ]  ETA: 0:00:01Evaluating over 9 metamodels:  56%[=============&gt;           ]  ETA: 0:00:01Evaluating over 9 metamodels:  67%[================&gt;        ]  ETA: 0:00:01Evaluating over 9 metamodels:  78%[===================&gt;     ]  ETA: 0:00:00Evaluating over 9 metamodels:  89%[======================&gt;  ]  ETA: 0:00:00Evaluating over 9 metamodels: 100%[=========================] Time: 0:00:01\n\n\nDecisionTreeClassifier(\n  max_depth = 5, \n  min_samples_leaf = 1, \n  min_samples_split = 2, \n  min_purity_increase = 0.0, \n  n_subfeatures = 0, \n  post_prune = false, \n  merge_purity_threshold = 1.0, \n  display_depth = 5, \n  feature_importance = :impurity, \n  rng = TaskLocalRNG())\n\n\n\n\n\nDibujar la curva de aprendizaje del modelo en funci√≥n de la profundidad del √°rbol de decisi√≥n.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n learning_curve del paquete MLJ para dibujar la curva de aprendizaje. Los par√°metros m√°s importantes de esta funci√≥n son:\n\nmach: Indica la m√°quina de aprendizaje a utilizar.\nrange: Indica el rango de valores a utilizar para ajustar los par√°metros del modelo.\nresampling: Indica el m√©todo de muestreo para definir los conjuntos de entrenamiento y test.\nmeasure: Indica la m√©trica a utilizar para evaluar el modelo.\nrngs: Indica la semilla para la generaci√≥n de n√∫meros aleatorios. Se pueden indicar varias semillas en un vector y se genera una curva de aprendizaje para cada semilla.\n\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Instanciamos el modelo de √°rbol de decisi√≥n.\narbol = Tree()\n# Definimos una m√°quina de aprendizaje con el modelo, las variables predictivas y la variable objetivo.\nmach = machine(arbol, X, y)\n# Definimos el rango de valores a utilizar para ajustar los par√°metros del modelo.\nr = range(arbol, :max_depth, lower=2, upper=10)\n# Dibujamos la curva de aprendizaje.\ncurva = learning_curve(mach, range = r, resampling = StratifiedCV(rng = 123), measure = accuracy)\n# Dibujamos la curva de aprendizaje.\nfig = Figure()\nax = Axis(fig[1, 1], title = \"Curva de aprendizaje\", xlabel = \"Profundidad del √°rbol\", ylabel = \"Precisi√≥n\")\nMakie.scatter!(ax, curva.parameter_values, curva.measurements)\nfig\n\n[ Info: Training machine(ProbabilisticTunedModel(model = DecisionTreeClassifier(max_depth = -1, ‚Ä¶), ‚Ä¶), ‚Ä¶).\n[ Info: Attempting to evaluate 9 models.\nEvaluating over 9 metamodels:  22%[=====&gt;                   ]  ETA: 0:00:01Evaluating over 9 metamodels:  33%[========&gt;                ]  ETA: 0:00:01Evaluating over 9 metamodels:  44%[===========&gt;             ]  ETA: 0:00:01Evaluating over 9 metamodels:  56%[=============&gt;           ]  ETA: 0:00:01Evaluating over 9 metamodels:  67%[================&gt;        ]  ETA: 0:00:01Evaluating over 9 metamodels:  78%[===================&gt;     ]  ETA: 0:00:00Evaluating over 9 metamodels:  89%[======================&gt;  ]  ETA: 0:00:00Evaluating over 9 metamodels: 100%[=========================] Time: 0:00:01\n‚îå Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n‚îî @ Makie ~/.julia/packages/Makie/ux0Te/src/scenes.jl:238\n\n\n\n\n\n\n\n\n\n\n\n\nConstruir un √°rbol de decisi√≥n con la profundidad m√°xima que da mejor resultado y visualizarlo.\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Instanciamos el modelo de √°rbol de decisi√≥n.\narbol = Tree(max_depth = 4)\n# Definimos una m√°quina de aprendizaje con el modelo, las variables predictivas y la variable objetivo.\nmach = machine(arbol, X, y)\n# Ajustamos los par√°metros del modelo.\nMLJ.fit!(mach)\n# Visualizamos el √°rbol de decisi√≥n.\nfitted_params(mach).tree\n\n[ Info: Training machine(DecisionTreeClassifier(max_depth = 4, ‚Ä¶), ‚Ä¶).\n\n\nalcohol &lt; 10.62\n‚îú‚îÄ meses_barrica &lt; 8.5\n‚îÇ  ‚îú‚îÄ acided_volatil &lt; 0.3125\n‚îÇ  ‚îÇ  ‚îú‚îÄ acided_volatil &lt; 0.2025\n‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ  ‚òπÔ∏è  (408/496)\n‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ  ‚òπÔ∏è  (1095/1172)\n‚îÇ  ‚îÇ  ‚îî‚îÄ meses_barrica &lt; 5.5\n‚îÇ  ‚îÇ     ‚îú‚îÄ  ‚òπÔ∏è  (1334/1345)\n‚îÇ  ‚îÇ     ‚îî‚îÄ  ‚òπÔ∏è  (51/58)\n‚îÇ  ‚îî‚îÄ  üòä  (25/25)\n‚îî‚îÄ meses_barrica &lt; 12.5\n   ‚îú‚îÄ cloruro_sodico &lt; 0.0455\n   ‚îÇ  ‚îú‚îÄ alcohol &lt; 12.55\n   ‚îÇ  ‚îÇ  ‚îú‚îÄ  ‚òπÔ∏è  (751/1160)\n   ‚îÇ  ‚îÇ  ‚îî‚îÄ  üòä  (185/286)\n   ‚îÇ  ‚îî‚îÄ meses_barrica &lt; 10.5\n   ‚îÇ     ‚îú‚îÄ  ‚òπÔ∏è  (552/629)\n   ‚îÇ     ‚îî‚îÄ  üòä  (25/43)\n   ‚îî‚îÄ alcohol &lt; 14.45\n      ‚îú‚îÄ  üòä  (105/105)\n      ‚îî‚îÄ  ‚òπÔ∏è  (1/1)\n\n\n\n\n\n¬øCu√°l es la importancia de cada variable en el modelo?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n feature_importances del paquete DecisionTree para calcular la importancia de cada variable.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\n# Calculamos la importancia de cada variable.\nfeature_importances(mach)\n\n13-element Vector{Pair{Symbol, Float64}}:\n              :alcohol =&gt; 0.5303315899204789\n        :meses_barrica =&gt; 0.26854115615561525\n       :acided_volatil =&gt; 0.1040970236546446\n       :cloruro_sodico =&gt; 0.09703023026926123\n                 :tipo =&gt; 0.0\n          :acided_fija =&gt; 0.0\n        :acido_citrico =&gt; 0.0\n      :azucar_residual =&gt; 0.0\n :dioxido_azufre_libre =&gt; 0.0\n :dioxido_azufre_total =&gt; 0.0\n             :densidad =&gt; 0.0\n                   :ph =&gt; 0.0\n             :sulfatos =&gt; 0.0\n\n\n\n\n\nPredecir la calidad de los 10 primeros vinos del conjunto de ejemplos.\n\n\n\n\n\n\nAyuda\n\n\n\n\n\nUsar la funci√≥n predict del paquete DecisionTree para predecir las probabilidades de pertenecer a cada clase un ejemplo o conjunto de ejemplos.\nUsar la funci√≥n predict_mode del paquete DecisionTree para predecir la clase de un ejemplo o conjunto de ejemplos.\n\n\n\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\nPrimero calculamos las probabilidades de cada clase.\n\nMLJ.predict(mach, X[1:10, :])\n\n10-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt32, Float64}:\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.992,  üòä =&gt;0.00818)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.823,  üòä =&gt;0.177)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.992,  üòä =&gt;0.00818)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.992,  üòä =&gt;0.00818)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.647,  üòä =&gt;0.353)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.647,  üòä =&gt;0.353)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.647,  üòä =&gt;0.353)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.878,  üòä =&gt;0.122)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.992,  üòä =&gt;0.00818)\n UnivariateFinite{OrderedFactor{2}}( ‚òπÔ∏è =&gt;0.992,  üòä =&gt;0.00818)\n\n\nY ahora predecimos la clase.\n\npredict_mode(mach, X[1:10, :])\n\n10-element CategoricalArray{String,1,UInt32}:\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"\n \" ‚òπÔ∏è \"",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>√Årboles de decisi√≥n</span>"
    ]
  }
]